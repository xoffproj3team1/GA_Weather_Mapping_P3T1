{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv    # from Karen's or Khaled's code\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import select      # Not used\n",
    "import psycopg2\n",
    "import csv   # Not used\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "\n",
    "# import gzip    # Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_metar_gz=\"https://aviationweather.gov/data/cache/metars.cache.csv.gz\"\n",
    "url_TAF_gz=\"https://aviationweather.gov/data/cache/tafs.cache.csv.gz\"\n",
    "url_airsigmets_gz=\"https://aviationweather.gov/data/cache/airsigmets.cache.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve METAR data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>station_id</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>dewpoint_c</th>\n",
       "      <th>wind_dir_degrees</th>\n",
       "      <th>wind_speed_kt</th>\n",
       "      <th>wind_gust_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>maxT24hr_c</th>\n",
       "      <th>minT24hr_c</th>\n",
       "      <th>precip_in</th>\n",
       "      <th>pcp3hr_in</th>\n",
       "      <th>pcp6hr_in</th>\n",
       "      <th>pcp24hr_in</th>\n",
       "      <th>snow_in</th>\n",
       "      <th>vert_vis_ft</th>\n",
       "      <th>metar_type</th>\n",
       "      <th>elevation_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KVOA 010140Z AUTO 21007KT 10SM BKN039 22/09 A3...</td>\n",
       "      <td>KVOA</td>\n",
       "      <td>2024-01-01T01:40:00Z</td>\n",
       "      <td>29.2290</td>\n",
       "      <td>-87.7810</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>210</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KSEM 010140Z AUTO 16003KT 10SM CLR 03/02 A3014...</td>\n",
       "      <td>KSEM</td>\n",
       "      <td>2024-01-01T01:40:00Z</td>\n",
       "      <td>32.3367</td>\n",
       "      <td>-86.9836</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KQFX 010140Z AUTO 06001KT 4000 BR OVC003 01/00...</td>\n",
       "      <td>KQFX</td>\n",
       "      <td>2024-01-01T01:40:00Z</td>\n",
       "      <td>-99.9900</td>\n",
       "      <td>-99.9900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KQFV 010140Z AUTO 12001KT 9999 BKN043 01/M01 A...</td>\n",
       "      <td>KQFV</td>\n",
       "      <td>2024-01-01T01:40:00Z</td>\n",
       "      <td>-99.9900</td>\n",
       "      <td>-99.9900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KQEW 010140Z AUTO 04002KT 0400 // CLR 01/M00 A...</td>\n",
       "      <td>KQEW</td>\n",
       "      <td>2024-01-01T01:40:00Z</td>\n",
       "      <td>-99.9900</td>\n",
       "      <td>-99.9900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text station_id  \\\n",
       "0  KVOA 010140Z AUTO 21007KT 10SM BKN039 22/09 A3...       KVOA   \n",
       "1  KSEM 010140Z AUTO 16003KT 10SM CLR 03/02 A3014...       KSEM   \n",
       "2  KQFX 010140Z AUTO 06001KT 4000 BR OVC003 01/00...       KQFX   \n",
       "3  KQFV 010140Z AUTO 12001KT 9999 BKN043 01/M01 A...       KQFV   \n",
       "4  KQEW 010140Z AUTO 04002KT 0400 // CLR 01/M00 A...       KQEW   \n",
       "\n",
       "       observation_time  latitude  longitude  temp_c  dewpoint_c  \\\n",
       "0  2024-01-01T01:40:00Z   29.2290   -87.7810    22.0         9.0   \n",
       "1  2024-01-01T01:40:00Z   32.3367   -86.9836     3.0         2.0   \n",
       "2  2024-01-01T01:40:00Z  -99.9900   -99.9900     1.0         0.0   \n",
       "3  2024-01-01T01:40:00Z  -99.9900   -99.9900     1.0        -1.0   \n",
       "4  2024-01-01T01:40:00Z  -99.9900   -99.9900     1.0         0.0   \n",
       "\n",
       "  wind_dir_degrees  wind_speed_kt  wind_gust_kt  ... maxT24hr_c  minT24hr_c  \\\n",
       "0              210            7.0           NaN  ...        NaN         NaN   \n",
       "1              160            3.0           NaN  ...        NaN         NaN   \n",
       "2               60            1.0           NaN  ...        NaN         NaN   \n",
       "3              120            1.0           NaN  ...        NaN         NaN   \n",
       "4               40            2.0           NaN  ...        NaN         NaN   \n",
       "\n",
       "   precip_in pcp3hr_in pcp6hr_in pcp24hr_in snow_in vert_vis_ft metar_type  \\\n",
       "0        NaN       NaN       NaN        NaN     NaN         NaN      METAR   \n",
       "1        NaN       NaN       NaN        NaN     NaN         NaN      METAR   \n",
       "2        NaN       NaN       NaN        NaN     NaN         NaN      METAR   \n",
       "3        NaN       NaN       NaN        NaN     NaN         NaN      METAR   \n",
       "4        NaN       NaN       NaN        NaN     NaN         NaN      METAR   \n",
       "\n",
       "  elevation_m  \n",
       "0        53.0  \n",
       "1        48.0  \n",
       "2      9999.0  \n",
       "3      9999.0  \n",
       "4      9999.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to metar\n",
    "metar_data_df = pd.read_csv(url_metar_gz, header=5, compression='gzip')\n",
    "metar_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# metar_json = json.loads(json.dumps(list(metar_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(metar_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(metar_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert some columns to INT\n",
    "# cols=['wind_dir_degrees','wind_speed_kt','wind_gust_kt','cloud_base_ft_agl','cloud_base_ft_agl.2',\\\n",
    "#     'cloud_base_ft_agl.3','vert_vis_ft','elevation_m']\n",
    "# metar_data_df[cols]=metar_data_df[cols].apply(pd.to_numeric, errors='coerce', downcast='integer', axis=1) # Does not appear to convert to INT, but to FLOAT64\n",
    "# metar_data_df[cols]=metar_data_df[cols].astype(int)   # Cannot convert NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "metar_string=json.dumps(list(metar_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"metar_data.json\")  # To be removed if logic.js cannot read from Resources\n",
    "output_path = os.path.join(\"\", \"metar_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(metar_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the dataframe as a csv file for future import to database (not needed anymore)\n",
    "# output_path2 = os.path.join(\"\", \"metar_data.csv\")\n",
    "# metar_data_df.to_csv(output_path2, index=False)\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To refresh the metar table in the Render database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the metar table\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DELETE FROM metar;\")    # Deletes all the rows but keep the table\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repopulate the empty table from a json file\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"set search_path to public\") # https://dba.stackexchange.com/questions/268365/using-python-to-insert-json-into-postgresql\n",
    "\n",
    "with open('metar_data.json') as file:\n",
    "    data = file.read()\n",
    "\n",
    "query_sql = \"\"\"\n",
    "INSERT INTO metar SELECT * FROM\n",
    "json_populate_recordset(NULL::metar, %s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_sql, (data,))\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download a new json file made of the joining of airport data and weather data__ (not used anymore: To be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with all the active public airport with or without weather information.\n",
    "# # Will be used to populate the makers that do not have METAR information.\n",
    "# # There is only one row per airport so only one runway is listed even if the airport as more.\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "# # query=\"\"\"\n",
    "# #     SELECT DISTINCT ON (arpt_id)\n",
    "# # \tarpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, long_decimal, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text\n",
    "# #     FROM apt_rwy\n",
    "# #     JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# #     FULL JOIN metar ON metar.station_id = apt_base.icao_id\n",
    "# #     WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O';\n",
    "# #     \"\"\"\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT DISTINCT ON (arpt_id)\n",
    "#     arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "# CASE\n",
    "# \tWHEN metar.station_id IS NOT NULL\n",
    "# \tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "# \tWHEN metar.station_id IS NULL\n",
    "# \tTHEN site_type_code='A'\n",
    "# END\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# arpt_weather_query_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save the df as a CSV file. Might not be needed if we only use JSON    TO BE REMOVED?\n",
    "# # arpt_weather_query_df.to_csv (r'airport_weather_data.csv', index = False) # place 'r' before the path name\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# arpt_weather_string=json.dumps(list(arpt_weather_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_weather_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(arpt_weather_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arpt_weather_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(arpt_weather_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve TAF data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch, load, and decompress the data relative to TAF  (working but not used for now)\n",
    "# taf_data_df = pd.read_csv(url_TAF_gz, header=5,index_col=False, compression='gzip',dtype='str',low_memory=False)\n",
    "# taf_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format  (working but not used for now)\n",
    "# taf_json = json.loads(json.dumps(list(taf_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(taf_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the dataframe to a dictionary then to a JSON string  (working but not used for now)\n",
    "# taf_string=json.dumps(list(taf_data_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"taf_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(taf_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve AIRMET and SIGMET polygons data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lon:lat points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS32 KKCI 010055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T00:55:00Z</td>\n",
       "      <td>2024-01-01T01:54:59Z</td>\n",
       "      <td>-107:49;-107:31.79;-106.52:31.78;-106.48:31.75...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS33 KKCI 010055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T00:55:00Z</td>\n",
       "      <td>2024-01-01T01:54:59Z</td>\n",
       "      <td>-122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS31 KKCI 010055 \u0007SIGE  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T00:55:00Z</td>\n",
       "      <td>2024-01-01T01:54:59Z</td>\n",
       "      <td>-87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSUS32 KKCI 010155 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T01:55:00Z</td>\n",
       "      <td>2024-01-01T03:55:00Z</td>\n",
       "      <td>-107:49;-107:31.79;-106.52:31.78;-106.48:31.75...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSUS31 KKCI 010155 \u0007SIGE  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T01:55:00Z</td>\n",
       "      <td>2024-01-01T03:55:00Z</td>\n",
       "      <td>-87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS32 KKCI 010055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-01T00:55:00Z   \n",
       "1  WSUS33 KKCI 010055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....  2024-01-01T00:55:00Z   \n",
       "2  WSUS31 KKCI 010055 \u0007SIGE  \u0007CONVECTIVE SIGMET.....  2024-01-01T00:55:00Z   \n",
       "3  WSUS32 KKCI 010155 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-01T01:55:00Z   \n",
       "4  WSUS31 KKCI 010155 \u0007SIGE  \u0007CONVECTIVE SIGMET.....  2024-01-01T01:55:00Z   \n",
       "\n",
       "          valid_time_to                                     lon:lat points  \\\n",
       "0  2024-01-01T01:54:59Z  -107:49;-107:31.79;-106.52:31.78;-106.48:31.75...   \n",
       "1  2024-01-01T01:54:59Z  -122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...   \n",
       "2  2024-01-01T01:54:59Z  -87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...   \n",
       "3  2024-01-01T03:55:00Z  -107:49;-107:31.79;-106.52:31.78;-106.48:31.75...   \n",
       "4  2024-01-01T03:55:00Z  -87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...   \n",
       "\n",
       "   min_ft_msl  max_ft_msl  movement_dir_degrees  movement_speed_kt  \\\n",
       "0         NaN         NaN                   NaN                NaN   \n",
       "1         NaN         NaN                   NaN                NaN   \n",
       "2         NaN         NaN                   NaN                NaN   \n",
       "3         NaN         NaN                   NaN                NaN   \n",
       "4         NaN         NaN                   NaN                NaN   \n",
       "\n",
       "       hazard severity airsigmet_type  \n",
       "0  CONVECTIVE        1         SIGMET  \n",
       "1  CONVECTIVE        1         SIGMET  \n",
       "2  CONVECTIVE        1         SIGMET  \n",
       "3  CONVECTIVE        1         SIGMET  \n",
       "4  CONVECTIVE        1         SIGMET  "
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to Airmet and Sigmet\n",
    "airsigmet_data_df = pd.read_csv(url_airsigmets_gz, header=5, compression='gzip', encoding='utf-8')\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lat_lon_points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS32 KKCI 010055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T00:55:00Z</td>\n",
       "      <td>2024-01-01T01:54:59Z</td>\n",
       "      <td>[[49.0, -107.0], [31.79, -107.0], [31.78, -106...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS33 KKCI 010055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T00:55:00Z</td>\n",
       "      <td>2024-01-01T01:54:59Z</td>\n",
       "      <td>[[49.0, -122.77], [48.96, -123.12], [48.6, -12...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS31 KKCI 010055 \u0007SIGE  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T00:55:00Z</td>\n",
       "      <td>2024-01-01T01:54:59Z</td>\n",
       "      <td>[[27.48, -87.0], [27.48, -84.26], [24.0, -83.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSUS32 KKCI 010155 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T01:55:00Z</td>\n",
       "      <td>2024-01-01T03:55:00Z</td>\n",
       "      <td>[[49.0, -107.0], [31.79, -107.0], [31.78, -106...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSUS31 KKCI 010155 \u0007SIGE  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-01T01:55:00Z</td>\n",
       "      <td>2024-01-01T03:55:00Z</td>\n",
       "      <td>[[27.48, -87.0], [27.48, -84.26], [24.0, -83.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS32 KKCI 010055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-01T00:55:00Z   \n",
       "1  WSUS33 KKCI 010055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....  2024-01-01T00:55:00Z   \n",
       "2  WSUS31 KKCI 010055 \u0007SIGE  \u0007CONVECTIVE SIGMET.....  2024-01-01T00:55:00Z   \n",
       "3  WSUS32 KKCI 010155 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-01T01:55:00Z   \n",
       "4  WSUS31 KKCI 010155 \u0007SIGE  \u0007CONVECTIVE SIGMET.....  2024-01-01T01:55:00Z   \n",
       "\n",
       "          valid_time_to                                     lat_lon_points  \\\n",
       "0  2024-01-01T01:54:59Z  [[49.0, -107.0], [31.79, -107.0], [31.78, -106...   \n",
       "1  2024-01-01T01:54:59Z  [[49.0, -122.77], [48.96, -123.12], [48.6, -12...   \n",
       "2  2024-01-01T01:54:59Z  [[27.48, -87.0], [27.48, -84.26], [24.0, -83.0...   \n",
       "3  2024-01-01T03:55:00Z  [[49.0, -107.0], [31.79, -107.0], [31.78, -106...   \n",
       "4  2024-01-01T03:55:00Z  [[27.48, -87.0], [27.48, -84.26], [24.0, -83.0...   \n",
       "\n",
       "   min_ft_msl  max_ft_msl  movement_dir_degrees  movement_speed_kt  \\\n",
       "0         NaN         NaN                   NaN                NaN   \n",
       "1         NaN         NaN                   NaN                NaN   \n",
       "2         NaN         NaN                   NaN                NaN   \n",
       "3         NaN         NaN                   NaN                NaN   \n",
       "4         NaN         NaN                   NaN                NaN   \n",
       "\n",
       "       hazard severity airsigmet_type  \n",
       "0  CONVECTIVE        1         SIGMET  \n",
       "1  CONVECTIVE        1         SIGMET  \n",
       "2  CONVECTIVE        1         SIGMET  \n",
       "3  CONVECTIVE        1         SIGMET  \n",
       "4  CONVECTIVE        1         SIGMET  "
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace with <br> in raw_text\n",
    "# airsigmet_data_df['raw_text'].str.replace(r' \\x07','<br>')\n",
    "# airsigmet_data_df.replace(r' x07','<br>', regex=True)\n",
    "\n",
    "# To convert the points delimiting the areas into something Leaflet-friendly\n",
    "for j in range(len(airsigmet_data_df)):\n",
    "    test=airsigmet_data_df.iloc[j]['lon:lat points']\n",
    "    if  pd.isna(test)!=True:    # Test if the cell is not NaN\n",
    "        test1=test.split(';')\n",
    "        for i in range(len(test1)):\n",
    "            test1[i]=test1[i].split(':')    # Creates list of coordinates\n",
    "            test1[i][0],test1[i][1]=float(test1[i][1]),float(test1[i][0])   # Swap lon:lat to lat:lon\n",
    "        airsigmet_data_df.at[j,'lon:lat points']=test1\n",
    "\n",
    "    # shift cells for missing column\n",
    "    test2=airsigmet_data_df.iloc[j]['airsigmet_type']\n",
    "    if  pd.isna(test2)==True:    # Test if the cell is NaN\n",
    "        airsigmet_data_df.at[j,'airsigmet_type']=airsigmet_data_df.at[j,'severity']\n",
    "        airsigmet_data_df.at[j,'severity']=airsigmet_data_df.at[j,'hazard']\n",
    "        airsigmet_data_df.at[j,'hazard']=airsigmet_data_df.at[j,'movement_speed_kt']\n",
    "        airsigmet_data_df.at[j,'movement_speed_kt']=airsigmet_data_df.at[j,'movement_dir_degrees']\n",
    "        airsigmet_data_df.at[j,'movement_dir_degrees']=airsigmet_data_df.at[j,'max_ft_msl']\n",
    "        airsigmet_data_df.at[j,'max_ft_msl']=airsigmet_data_df.at[j,'min_ft_msl']\n",
    "        airsigmet_data_df.at[j,'min_ft_msl']=\"NaN\"\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "airsigmet_data_df.rename(columns={\"lon:lat points\":\"lat_lon_points\"}, inplace=True) # Update the column name\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# airsigmet_json = json.loads(json.dumps(list(airsigmet_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(airsigmet_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "airsigmet_string=json.dumps(list(airsigmet_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"airsigmet_data.json\")\n",
    "output_path = os.path.join(\"\", \"airsigmet_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airsigmet_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download headwing and crosswind informations for all runways__ (Not used anymore: to be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with the wind information relative to all runways.\n",
    "# # Will be used to update the makers for all airports.\n",
    "# # There are multiple rows per airport (one per runway).\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT arpt_id, icao_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "# ROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "# ROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "# ROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "# ROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# JOIN apt_rwy_end ON apt_base.site_no = apt_rwy_end.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND arpt_status='O' AND site_type_code='A' AND (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND metar.wind_dir_degrees != 'VRB'\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# rwy_wind_query_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# rwy_wind_string=json.dumps(list(rwy_wind_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"rwy_wind_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rwy_wind_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Retrieve all data to position the circles for all airports and create the popup text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the output of a consolidated query across multiple tables with all information pertinent to an airport.\n",
    "# Will be used to update the makers for all airports.\n",
    "# There are multiple rows per airport (one per runway).\n",
    "# More parameters can be added to complete the info on the popup window.\n",
    "# Will be used to consolidate the information in the popups\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "query=\"\"\"\n",
    "-- Query to get METAR information for each airport as a VIEW\n",
    "DROP VIEW IF EXISTS all_circles_view;\n",
    "CREATE VIEW all_circles_view AS\n",
    "SELECT \n",
    "arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "-- , metar.wind_speed_kt\n",
    "FROM apt_rwy\n",
    "JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "CASE\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Query to get wind information for each runway as a VIEW\n",
    "DROP VIEW IF EXISTS all_rwy_xwind_view;\n",
    "CREATE VIEW all_rwy_xwind_view AS\n",
    "SELECT arpt_id, icao_id, arpt_name, apt_base.tpa, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy.rwy_width, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, apt_rwy_end.right_hand_traffic_pat_flag, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "\tROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "\tROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "\tROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "\tROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "FROM apt_rwy_end\n",
    "FULL JOIN apt_base ON apt_base.site_no = apt_rwy_end.site_no\n",
    "FULL JOIN apt_rwy ON apt_base.site_no = apt_rwy.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND arpt_status='O' AND\n",
    "CASE -- by not have the CASE, we were not providing the rwy length of the airports without METAR\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tAND metar.wind_dir_degrees != 'VRB'\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Merge the two VIEWS\n",
    "SELECT \tall_circles_view.arpt_id, all_circles_view.icao_id, all_circles_view.station_id, all_circles_view.arpt_name, all_circles_view.lat_decimal, all_circles_view.long_decimal, all_circles_view.elev, all_rwy_xwind_view.tpa,\n",
    "\t\tall_circles_view.rwy_id, all_rwy_xwind_view.rwy_end_id, all_rwy_xwind_view.rwy_len, all_rwy_xwind_view.rwy_width, all_rwy_xwind_view.right_hand_traffic_pat_flag,\n",
    "\t\tall_rwy_xwind_view.cross_wind, all_rwy_xwind_view.head_wind, all_rwy_xwind_view.gust_cross_wind, all_rwy_xwind_view.gust_head_wind,\t\t\n",
    "\t\tall_rwy_xwind_view.true_alignment,\n",
    "\t\tall_rwy_xwind_view.wind_dir_degrees, all_rwy_xwind_view.wind_speed_kt, all_rwy_xwind_view.wind_gust_kt,\n",
    "\t\tall_circles_view.flight_category,  all_circles_view.visibility_statute_mi, all_circles_view.cloud_base_ft_agl,\t\t\n",
    "\t\tall_circles_view.observation_time, all_circles_view.raw_text\n",
    "FROM all_circles_view\n",
    "FULL JOIN all_rwy_xwind_view ON all_circles_view.arpt_id = all_rwy_xwind_view.arpt_id\n",
    "AND all_circles_view.rwy_id=all_rwy_xwind_view.rwy_id\n",
    "WHERE all_circles_view.rwy_id NOT LIKE 'H%'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "engine=create_engine(db_url)\n",
    "with engine.begin() as conn:\n",
    "    results=conn.execute(\n",
    "        text(query)\n",
    "    )\n",
    "\n",
    "airport_info_query_raw_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "# airport_info_string=json.dumps(list(airport_info_query_raw_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_info_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpt_id</th>\n",
       "      <th>icao_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>arpt_name</th>\n",
       "      <th>lat_decimal</th>\n",
       "      <th>long_decimal</th>\n",
       "      <th>elev</th>\n",
       "      <th>rwy_id</th>\n",
       "      <th>rwy_end_id</th>\n",
       "      <th>rwy_len</th>\n",
       "      <th>...</th>\n",
       "      <th>gust_head_wind</th>\n",
       "      <th>true_alignment</th>\n",
       "      <th>wind_dir_degrees</th>\n",
       "      <th>wind_speed_kt</th>\n",
       "      <th>wind_gust_kt</th>\n",
       "      <th>flight_category</th>\n",
       "      <th>visibility_statute_mi</th>\n",
       "      <th>cloud_base_ft_agl</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0J0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ABBEVILLE MUNI</td>\n",
       "      <td>31.600222</td>\n",
       "      <td>-85.238308</td>\n",
       "      <td>463.1</td>\n",
       "      <td>17/35</td>\n",
       "      <td>17</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0J0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ABBEVILLE MUNI</td>\n",
       "      <td>31.600222</td>\n",
       "      <td>-85.238308</td>\n",
       "      <td>463.1</td>\n",
       "      <td>17/35</td>\n",
       "      <td>35</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>352.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2A8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ADDISON MUNI</td>\n",
       "      <td>34.217142</td>\n",
       "      <td>-87.158158</td>\n",
       "      <td>786.0</td>\n",
       "      <td>05/23</td>\n",
       "      <td>05</td>\n",
       "      <td>2644.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2A8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ADDISON MUNI</td>\n",
       "      <td>34.217142</td>\n",
       "      <td>-87.158158</td>\n",
       "      <td>786.0</td>\n",
       "      <td>05/23</td>\n",
       "      <td>23</td>\n",
       "      <td>2644.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EET</td>\n",
       "      <td>KEET</td>\n",
       "      <td>KEET</td>\n",
       "      <td>SHELBY COUNTY</td>\n",
       "      <td>33.177778</td>\n",
       "      <td>-86.783222</td>\n",
       "      <td>585.6</td>\n",
       "      <td>16/34</td>\n",
       "      <td>16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.0</td>\n",
       "      <td>200</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VFR</td>\n",
       "      <td>10+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-31T21:53:00Z</td>\n",
       "      <td>KEET 312153Z AUTO 20008KT 10SM CLR 14/M01 A301...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  arpt_id icao_id station_id       arpt_name  lat_decimal  long_decimal  \\\n",
       "0     0J0    None       None  ABBEVILLE MUNI    31.600222    -85.238308   \n",
       "1     0J0    None       None  ABBEVILLE MUNI    31.600222    -85.238308   \n",
       "2     2A8    None       None    ADDISON MUNI    34.217142    -87.158158   \n",
       "3     2A8    None       None    ADDISON MUNI    34.217142    -87.158158   \n",
       "4     EET    KEET       KEET   SHELBY COUNTY    33.177778    -86.783222   \n",
       "\n",
       "    elev rwy_id rwy_end_id  rwy_len  ...  gust_head_wind  true_alignment  \\\n",
       "0  463.1  17/35         17   2900.0  ...             NaN           172.0   \n",
       "1  463.1  17/35         35   2900.0  ...             NaN           352.0   \n",
       "2  786.0  05/23         05   2644.0  ...             NaN            49.0   \n",
       "3  786.0  05/23         23   2644.0  ...             NaN           229.0   \n",
       "4  585.6  16/34         16   5000.0  ...             NaN           157.0   \n",
       "\n",
       "   wind_dir_degrees  wind_speed_kt  wind_gust_kt flight_category  \\\n",
       "0              None            NaN           NaN            None   \n",
       "1              None            NaN           NaN            None   \n",
       "2              None            NaN           NaN            None   \n",
       "3              None            NaN           NaN            None   \n",
       "4               200            8.0           NaN             VFR   \n",
       "\n",
       "   visibility_statute_mi  cloud_base_ft_agl      observation_time  \\\n",
       "0                   None                NaN                  None   \n",
       "1                   None                NaN                  None   \n",
       "2                   None                NaN                  None   \n",
       "3                   None                NaN                  None   \n",
       "4                    10+                NaN  2023-12-31T21:53:00Z   \n",
       "\n",
       "                                            raw_text  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4  KEET 312153Z AUTO 20008KT 10SM CLR 14/M01 A301...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airport_info_query_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
       "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
       "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
       "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
       "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
       "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
       "       'raw_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_info_query_raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View length: 13611\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rwy_rwy_width'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Christophe\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Christophe\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Christophe\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rwy_rwy_width'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[880], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m         popup_text\u001b[38;5;241m=\u001b[39mpopup_text\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<br>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m<div class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrwy_len\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Runway length: \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(airport_info_query_raw_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrwy_len\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (ft)</div>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(airport_info_query_raw_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrwy_width\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m         popup_text\u001b[38;5;241m=\u001b[39mpopup_text\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<br>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m<div class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrwy_rwy_width\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Runway width: \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[43mairport_info_query_raw_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrwy_rwy_width\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (ft)</div>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     50\u001b[0m     first_rwy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (pd\u001b[38;5;241m.\u001b[39misna(airport_info_query_raw_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_text\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;241m&\u001b[39m pd\u001b[38;5;241m.\u001b[39misna(airport_info_query_raw_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_alignment\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m|\u001b[39m (airport_info_query_raw_df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright_hand_traffic_pat_flag\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Christophe\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Christophe\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\Christophe\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rwy_rwy_width'"
     ]
    }
   ],
   "source": [
    "# Consolidation of the database with only one row per airport regardless of the number of runways\n",
    "\n",
    "airport_info_query_df=pd.DataFrame(columns=['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
    "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
    "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
    "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
    "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
    "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
    "       'raw_text'])\n",
    "\n",
    "airport_info_query_df[\"popup_text\"]=np.nan\n",
    "\n",
    "first_row=True\n",
    "first_rwy=True\n",
    "\n",
    "a=len(airport_info_query_raw_df)\n",
    "print(f\"View length: {a}\")\n",
    "for i in range (a):\n",
    "    if first_row:\n",
    "       k=i\n",
    "       airport_info_query_df.loc[airport_info_query_raw_df.index[i]] = airport_info_query_raw_df.iloc[i]\n",
    "       popup_text=\"\"\"<div class=\"arpt_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_id\"]+'</div>'\n",
    "\n",
    "       if airport_info_query_raw_df.iloc[i][\"icao_id\"] is not None:\n",
    "           popup_text=popup_text+\"\"\"<div class=\"icao_id\"> / \"\"\"+airport_info_query_raw_df.iloc[i][\"icao_id\"]+'</div>'\n",
    "\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"arpt_name\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_name\"]+'</div>'\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"elev\">Airport Elevation: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"tpa\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+int(airport_info_query_raw_df.iloc[i][\"tpa\"])))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "       else:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA (estimated): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+1000))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "             \n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"visibility_statute_mi\">Airport visibility: \"\"\"+airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"]+' (SM)</div>'\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"cloud_base_ft_agl\">Airport ceiling: \"\"\"+str(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])+' (ft AGL)</div>'\n",
    "\n",
    "       first_row=False\n",
    "\n",
    "    if first_rwy:\n",
    "        popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_id\"> Runway \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_id\"]+' </div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_len\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_len\"> Runway length: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_len\"]))+' (ft)</div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_width\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_width\"> Runway width: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_width\"]))+' (ft)</div>'\n",
    "        first_rwy=False\n",
    "\n",
    "    if (pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False & pd.isna(airport_info_query_raw_df.iloc[i][\"true_alignment\"])==False) | (airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y'):\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_end_id\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_end_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_end_id\"]+' :</div>'\n",
    "            if airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y':\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"RP\"> RP </div>\"\"\"\n",
    "\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"cross_wind\">Crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"head_wind\">Headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_cross_wind\">Gust crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_head_wind\">Gust headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "\n",
    "    if i<a-1:\n",
    "        if airport_info_query_raw_df.iloc[i+1][\"arpt_id\"]!=airport_info_query_raw_df.iloc[i][\"arpt_id\"]:\n",
    "            if pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False:\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"raw_text\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"raw_text\"]+'</div>'\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"observation_time\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"observation_time\"]+'</div>'\n",
    "            else:\n",
    "                popup_text=popup_text+'<br> <div class=\"raw_text\">No weather information</div>'\n",
    "\n",
    "            airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "            # print(f\"k={k}, i={i}\")\n",
    "            # print(popup_text)\n",
    "            first_row=True\n",
    "            first_rwy=True\n",
    "        elif airport_info_query_raw_df.iloc[i+1][\"rwy_id\"]!=airport_info_query_raw_df.iloc[i][\"rwy_id\"]:\n",
    "            first_rwy=True\n",
    "\n",
    "    if i==a-1:\n",
    "        airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "airport_info_string=json.dumps(list(airport_info_query_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "output_path = os.path.join(\"\", \"airport_info_full_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airport_info_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block\n",
    "        \n",
    "\n",
    "\n",
    "# airport_info_query_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpt_id</th>\n",
       "      <th>icao_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>arpt_name</th>\n",
       "      <th>lat_decimal</th>\n",
       "      <th>long_decimal</th>\n",
       "      <th>elev</th>\n",
       "      <th>tpa</th>\n",
       "      <th>rwy_id</th>\n",
       "      <th>rwy_end_id</th>\n",
       "      <th>...</th>\n",
       "      <th>true_alignment</th>\n",
       "      <th>wind_dir_degrees</th>\n",
       "      <th>wind_speed_kt</th>\n",
       "      <th>wind_gust_kt</th>\n",
       "      <th>flight_category</th>\n",
       "      <th>visibility_statute_mi</th>\n",
       "      <th>cloud_base_ft_agl</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>popup_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>BLU</td>\n",
       "      <td>KBLU</td>\n",
       "      <td>KBLU</td>\n",
       "      <td>BLUE CANYON - NYACK</td>\n",
       "      <td>39.274972</td>\n",
       "      <td>-120.70975</td>\n",
       "      <td>5283.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15/33</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFR</td>\n",
       "      <td>10+</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2023-12-31T22:52:00Z</td>\n",
       "      <td>KBLU 312252Z AUTO 00000KT 10SM SCT004 BKN008 O...</td>\n",
       "      <td>&lt;div class=\"arpt_id\"&gt; BLU&lt;/div&gt;&lt;div class=\"ica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arpt_id icao_id station_id            arpt_name lat_decimal long_decimal  \\\n",
       "808     BLU    KBLU       KBLU  BLUE CANYON - NYACK   39.274972   -120.70975   \n",
       "\n",
       "       elev  tpa rwy_id rwy_end_id  ... true_alignment wind_dir_degrees  \\\n",
       "808  5283.5  NaN  15/33         15  ...            NaN                0   \n",
       "\n",
       "     wind_speed_kt  wind_gust_kt  flight_category  visibility_statute_mi  \\\n",
       "808            0.0           NaN              IFR                    10+   \n",
       "\n",
       "    cloud_base_ft_agl      observation_time  \\\n",
       "808             400.0  2023-12-31T22:52:00Z   \n",
       "\n",
       "                                              raw_text  \\\n",
       "808  KBLU 312252Z AUTO 00000KT 10SM SCT004 BKN008 O...   \n",
       "\n",
       "                                            popup_text  \n",
       "808  <div class=\"arpt_id\"> BLU</div><div class=\"ica...  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airport_info_query_df[airport_info_query_df['arpt_id']=='BLU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
