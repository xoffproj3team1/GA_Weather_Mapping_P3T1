{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv    # from Karen's or Khaled's code\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import select      # Not used\n",
    "import psycopg2\n",
    "import csv   # Not used\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "\n",
    "# import gzip    # Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_metar_gz=\"https://aviationweather.gov/data/cache/metars.cache.csv.gz\"\n",
    "url_TAF_gz=\"https://aviationweather.gov/data/cache/tafs.cache.csv.gz\"\n",
    "url_airsigmets_gz=\"https://aviationweather.gov/data/cache/airsigmets.cache.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve METAR data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>station_id</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>dewpoint_c</th>\n",
       "      <th>wind_dir_degrees</th>\n",
       "      <th>wind_speed_kt</th>\n",
       "      <th>wind_gust_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>maxT24hr_c</th>\n",
       "      <th>minT24hr_c</th>\n",
       "      <th>precip_in</th>\n",
       "      <th>pcp3hr_in</th>\n",
       "      <th>pcp6hr_in</th>\n",
       "      <th>pcp24hr_in</th>\n",
       "      <th>snow_in</th>\n",
       "      <th>vert_vis_ft</th>\n",
       "      <th>metar_type</th>\n",
       "      <th>elevation_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CYDN 030118Z AUTO 35008KT 9SM OVC024 M06/M08 A...</td>\n",
       "      <td>CYDN</td>\n",
       "      <td>2024-01-03T01:18:00Z</td>\n",
       "      <td>51.1000</td>\n",
       "      <td>-100.0570</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>350</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KLRD 030117Z 34008KT 6SM BR OVC007 12/11 A3005...</td>\n",
       "      <td>KLRD</td>\n",
       "      <td>2024-01-03T01:17:00Z</td>\n",
       "      <td>27.5510</td>\n",
       "      <td>-99.4614</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>340</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KFRM 030117Z AUTO 31004KT 10SM SCT027 M01/M04 ...</td>\n",
       "      <td>KFRM</td>\n",
       "      <td>2024-01-03T01:17:00Z</td>\n",
       "      <td>43.6455</td>\n",
       "      <td>-94.4168</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>310</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CYXY 030117Z 36006KT 10SM -SN BKN009 OVC018 M1...</td>\n",
       "      <td>CYXY</td>\n",
       "      <td>2024-01-03T01:17:00Z</td>\n",
       "      <td>60.7100</td>\n",
       "      <td>-135.0590</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>360</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>677.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYVL 030117Z AUTO VRB02KT 5SM HZ BKN014 M32/M3...</td>\n",
       "      <td>CYVL</td>\n",
       "      <td>2024-01-03T01:17:00Z</td>\n",
       "      <td>67.0210</td>\n",
       "      <td>-126.1290</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>VRB</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text station_id  \\\n",
       "0  CYDN 030118Z AUTO 35008KT 9SM OVC024 M06/M08 A...       CYDN   \n",
       "1  KLRD 030117Z 34008KT 6SM BR OVC007 12/11 A3005...       KLRD   \n",
       "2  KFRM 030117Z AUTO 31004KT 10SM SCT027 M01/M04 ...       KFRM   \n",
       "3  CYXY 030117Z 36006KT 10SM -SN BKN009 OVC018 M1...       CYXY   \n",
       "4  CYVL 030117Z AUTO VRB02KT 5SM HZ BKN014 M32/M3...       CYVL   \n",
       "\n",
       "       observation_time  latitude  longitude  temp_c  dewpoint_c  \\\n",
       "0  2024-01-03T01:18:00Z   51.1000  -100.0570    -6.0        -8.0   \n",
       "1  2024-01-03T01:17:00Z   27.5510   -99.4614    12.0        11.0   \n",
       "2  2024-01-03T01:17:00Z   43.6455   -94.4168    -1.0        -4.0   \n",
       "3  2024-01-03T01:17:00Z   60.7100  -135.0590   -14.0       -16.0   \n",
       "4  2024-01-03T01:17:00Z   67.0210  -126.1290   -32.0       -35.0   \n",
       "\n",
       "  wind_dir_degrees  wind_speed_kt  wind_gust_kt  ... maxT24hr_c  minT24hr_c  \\\n",
       "0              350            8.0           NaN  ...        NaN         NaN   \n",
       "1              340            8.0           NaN  ...        NaN         NaN   \n",
       "2              310            4.0           NaN  ...        NaN         NaN   \n",
       "3              360            6.0           NaN  ...        NaN         NaN   \n",
       "4              VRB            2.0           NaN  ...        NaN         NaN   \n",
       "\n",
       "   precip_in pcp3hr_in pcp6hr_in pcp24hr_in snow_in vert_vis_ft metar_type  \\\n",
       "0        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "1        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "2        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "3        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "4        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "\n",
       "  elevation_m  \n",
       "0       302.0  \n",
       "1       150.0  \n",
       "2       353.0  \n",
       "3       677.0  \n",
       "4       261.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to metar\n",
    "metar_data_df = pd.read_csv(url_metar_gz, header=5, compression='gzip')\n",
    "metar_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# metar_json = json.loads(json.dumps(list(metar_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(metar_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(metar_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert some columns to INT\n",
    "# cols=['wind_dir_degrees','wind_speed_kt','wind_gust_kt','cloud_base_ft_agl','cloud_base_ft_agl.2',\\\n",
    "#     'cloud_base_ft_agl.3','vert_vis_ft','elevation_m']\n",
    "# metar_data_df[cols]=metar_data_df[cols].apply(pd.to_numeric, errors='coerce', downcast='integer', axis=1) # Does not appear to convert to INT, but to FLOAT64\n",
    "# metar_data_df[cols]=metar_data_df[cols].astype(int)   # Cannot convert NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "metar_string=json.dumps(list(metar_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"metar_data.json\")  # To be removed if logic.js cannot read from Resources\n",
    "output_path = os.path.join(\"static\", \"metar_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(metar_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the dataframe as a csv file for future import to database (not needed anymore)\n",
    "# output_path2 = os.path.join(\"\", \"metar_data.csv\")\n",
    "# metar_data_df.to_csv(output_path2, index=False)\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To refresh the metar table in the Render database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the metar table\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DELETE FROM metar;\")    # Deletes all the rows but keep the table\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repopulate the empty table from a json file\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"set search_path to public\") # https://dba.stackexchange.com/questions/268365/using-python-to-insert-json-into-postgresql\n",
    "\n",
    "with open(output_path) as file:\n",
    "    data = file.read()\n",
    "\n",
    "query_sql = \"\"\"\n",
    "INSERT INTO metar SELECT * FROM\n",
    "json_populate_recordset(NULL::metar, %s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_sql, (data,))\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download a new json file made of the joining of airport data and weather data__ (not used anymore: To be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with all the active public airport with or without weather information.\n",
    "# # Will be used to populate the makers that do not have METAR information.\n",
    "# # There is only one row per airport so only one runway is listed even if the airport as more.\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "# # query=\"\"\"\n",
    "# #     SELECT DISTINCT ON (arpt_id)\n",
    "# # \tarpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, long_decimal, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text\n",
    "# #     FROM apt_rwy\n",
    "# #     JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# #     FULL JOIN metar ON metar.station_id = apt_base.icao_id\n",
    "# #     WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O';\n",
    "# #     \"\"\"\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT DISTINCT ON (arpt_id)\n",
    "#     arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "# CASE\n",
    "# \tWHEN metar.station_id IS NOT NULL\n",
    "# \tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "# \tWHEN metar.station_id IS NULL\n",
    "# \tTHEN site_type_code='A'\n",
    "# END\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# arpt_weather_query_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save the df as a CSV file. Might not be needed if we only use JSON    TO BE REMOVED?\n",
    "# # arpt_weather_query_df.to_csv (r'airport_weather_data.csv', index = False) # place 'r' before the path name\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# arpt_weather_string=json.dumps(list(arpt_weather_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_weather_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(arpt_weather_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arpt_weather_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(arpt_weather_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve TAF data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch, load, and decompress the data relative to TAF  (working but not used for now)\n",
    "# taf_data_df = pd.read_csv(url_TAF_gz, header=5,index_col=False, compression='gzip',dtype='str',low_memory=False)\n",
    "# taf_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format  (working but not used for now)\n",
    "# taf_json = json.loads(json.dumps(list(taf_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(taf_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the dataframe to a dictionary then to a JSON string  (working but not used for now)\n",
    "# taf_string=json.dumps(list(taf_data_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"taf_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(taf_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve AIRMET and SIGMET polygons data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lon:lat points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS31 KKCI 030155 \u0007SIGE  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>-87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS33 KKCI 030155 \u0007SIGW  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>-122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS32 KKCI 030155 \u0007SIGC  \u0007CONVECTIVE SIGMET 2...</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>-96.6626:32.0976;-95.272:31.6289;-95.1726:28.7...</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAUS41 KKCI 022045 \u0007BOSS WA 022045 \u0007AIRMET SIE...</td>\n",
       "      <td>2024-01-02T20:45:00Z</td>\n",
       "      <td>2024-01-03T02:45:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFR</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAUS41 KKCI 022045 \u0007BOSS WA 022045 \u0007AIRMET SIE...</td>\n",
       "      <td>2024-01-02T20:45:00Z</td>\n",
       "      <td>2024-01-03T02:45:00Z</td>\n",
       "      <td>-69.3144:47.5893;-68.7027:45.8869;-71.0532:44....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTN OBSCN</td>\n",
       "      <td>0</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS31 KKCI 030155 \u0007SIGE  \u0007CONVECTIVE SIGMET.....  2024-01-03T01:55:00Z   \n",
       "1  WSUS33 KKCI 030155 \u0007SIGW  \u0007CONVECTIVE SIGMET.....  2024-01-03T01:55:00Z   \n",
       "2  WSUS32 KKCI 030155 \u0007SIGC  \u0007CONVECTIVE SIGMET 2...  2024-01-03T01:55:00Z   \n",
       "3  WAUS41 KKCI 022045 \u0007BOSS WA 022045 \u0007AIRMET SIE...  2024-01-02T20:45:00Z   \n",
       "4  WAUS41 KKCI 022045 \u0007BOSS WA 022045 \u0007AIRMET SIE...  2024-01-02T20:45:00Z   \n",
       "\n",
       "          valid_time_to                                     lon:lat points  \\\n",
       "0  2024-01-03T03:55:00Z  -87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...   \n",
       "1  2024-01-03T03:55:00Z  -122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...   \n",
       "2  2024-01-03T03:55:00Z  -96.6626:32.0976;-95.272:31.6289;-95.1726:28.7...   \n",
       "3  2024-01-03T02:45:00Z                                                NaN   \n",
       "4  2024-01-03T02:45:00Z  -69.3144:47.5893;-68.7027:45.8869;-71.0532:44....   \n",
       "\n",
       "   min_ft_msl  max_ft_msl  movement_dir_degrees movement_speed_kt      hazard  \\\n",
       "0         NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "1         NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "2     34000.0         NaN                   NaN        CONVECTIVE      LT-MOD   \n",
       "3         NaN         NaN                   NaN               NaN         IFR   \n",
       "4         NaN         NaN                   NaN               NaN   MTN OBSCN   \n",
       "\n",
       "  severity airsigmet_type  \n",
       "0        1         SIGMET  \n",
       "1        1         SIGMET  \n",
       "2   SIGMET            NaN  \n",
       "3        1         AIRMET  \n",
       "4        0         AIRMET  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to Airmet and Sigmet\n",
    "airsigmet_data_df = pd.read_csv(url_airsigmets_gz, header=5, compression='gzip', encoding='utf-8')\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airsigmet_data_df[\"raw_text\"] = airsigmet_data_df[\"raw_text\"].replace(r'\\x07','\\n', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "airsigmet_data_df[\"raw_text\"] = airsigmet_data_df[\"raw_text\"].replace(r'\\x07','<br>', regex=True)   # Used to replace \\n that does not get decompressed as utf-8 and was converted as \\x07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# re.findall('[^\\w \\.-]', airsigmet_data_df['raw_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.sub('[^\\w \\.-]', \"\\n\", airsigmet_data_df['raw_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lon:lat points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS31 KKCI 030155 &lt;br&gt;SIGE  &lt;br&gt;CONVECTIVE SI...</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>-87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS33 KKCI 030155 &lt;br&gt;SIGW  &lt;br&gt;CONVECTIVE SI...</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>-122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS32 KKCI 030155 &lt;br&gt;SIGC  &lt;br&gt;CONVECTIVE SI...</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>-96.6626:32.0976;-95.272:31.6289;-95.1726:28.7...</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAUS41 KKCI 022045 &lt;br&gt;BOSS WA 022045 &lt;br&gt;AIRM...</td>\n",
       "      <td>2024-01-02T20:45:00Z</td>\n",
       "      <td>2024-01-03T02:45:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFR</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAUS41 KKCI 022045 &lt;br&gt;BOSS WA 022045 &lt;br&gt;AIRM...</td>\n",
       "      <td>2024-01-02T20:45:00Z</td>\n",
       "      <td>2024-01-03T02:45:00Z</td>\n",
       "      <td>-69.3144:47.5893;-68.7027:45.8869;-71.0532:44....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTN OBSCN</td>\n",
       "      <td>0</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS31 KKCI 030155 <br>SIGE  <br>CONVECTIVE SI...  2024-01-03T01:55:00Z   \n",
       "1  WSUS33 KKCI 030155 <br>SIGW  <br>CONVECTIVE SI...  2024-01-03T01:55:00Z   \n",
       "2  WSUS32 KKCI 030155 <br>SIGC  <br>CONVECTIVE SI...  2024-01-03T01:55:00Z   \n",
       "3  WAUS41 KKCI 022045 <br>BOSS WA 022045 <br>AIRM...  2024-01-02T20:45:00Z   \n",
       "4  WAUS41 KKCI 022045 <br>BOSS WA 022045 <br>AIRM...  2024-01-02T20:45:00Z   \n",
       "\n",
       "          valid_time_to                                     lon:lat points  \\\n",
       "0  2024-01-03T03:55:00Z  -87:27.48;-84.26:27.48;-83.01:24;-78.66:24;-79...   \n",
       "1  2024-01-03T03:55:00Z  -122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...   \n",
       "2  2024-01-03T03:55:00Z  -96.6626:32.0976;-95.272:31.6289;-95.1726:28.7...   \n",
       "3  2024-01-03T02:45:00Z                                                NaN   \n",
       "4  2024-01-03T02:45:00Z  -69.3144:47.5893;-68.7027:45.8869;-71.0532:44....   \n",
       "\n",
       "   min_ft_msl  max_ft_msl  movement_dir_degrees movement_speed_kt      hazard  \\\n",
       "0         NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "1         NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "2     34000.0         NaN                   NaN        CONVECTIVE      LT-MOD   \n",
       "3         NaN         NaN                   NaN               NaN         IFR   \n",
       "4         NaN         NaN                   NaN               NaN   MTN OBSCN   \n",
       "\n",
       "  severity airsigmet_type  \n",
       "0        1         SIGMET  \n",
       "1        1         SIGMET  \n",
       "2   SIGMET            NaN  \n",
       "3        1         AIRMET  \n",
       "4        0         AIRMET  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to Airmet and Sigmet\n",
    "# airsigmet_data_df = pd.read_csv(url_airsigmets_gz, header=5, compression='gzip', encoding='utf-8')\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lat_lon_points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS31 KKCI 030155 &lt;br&gt;SIGE  &lt;br&gt;CONVECTIVE SI...</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>[[27.48, -87.0], [27.48, -84.26], [24.0, -83.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS33 KKCI 030155 &lt;br&gt;SIGW  &lt;br&gt;CONVECTIVE SI...</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>[[49.0, -122.77], [48.96, -123.12], [48.6, -12...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS32 KKCI 030155 &lt;br&gt;SIGC  &lt;br&gt;CONVECTIVE SI...</td>\n",
       "      <td>2024-01-03T01:55:00Z</td>\n",
       "      <td>2024-01-03T03:55:00Z</td>\n",
       "      <td>[[32.0976, -96.6626], [31.6289, -95.272], [28....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAUS41 KKCI 022045 &lt;br&gt;BOSS WA 022045 &lt;br&gt;AIRM...</td>\n",
       "      <td>2024-01-02T20:45:00Z</td>\n",
       "      <td>2024-01-03T02:45:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFR</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAUS41 KKCI 022045 &lt;br&gt;BOSS WA 022045 &lt;br&gt;AIRM...</td>\n",
       "      <td>2024-01-02T20:45:00Z</td>\n",
       "      <td>2024-01-03T02:45:00Z</td>\n",
       "      <td>[[47.5893, -69.3144], [45.8869, -68.7027], [44...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTN OBSCN</td>\n",
       "      <td>0</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS31 KKCI 030155 <br>SIGE  <br>CONVECTIVE SI...  2024-01-03T01:55:00Z   \n",
       "1  WSUS33 KKCI 030155 <br>SIGW  <br>CONVECTIVE SI...  2024-01-03T01:55:00Z   \n",
       "2  WSUS32 KKCI 030155 <br>SIGC  <br>CONVECTIVE SI...  2024-01-03T01:55:00Z   \n",
       "3  WAUS41 KKCI 022045 <br>BOSS WA 022045 <br>AIRM...  2024-01-02T20:45:00Z   \n",
       "4  WAUS41 KKCI 022045 <br>BOSS WA 022045 <br>AIRM...  2024-01-02T20:45:00Z   \n",
       "\n",
       "          valid_time_to                                     lat_lon_points  \\\n",
       "0  2024-01-03T03:55:00Z  [[27.48, -87.0], [27.48, -84.26], [24.0, -83.0...   \n",
       "1  2024-01-03T03:55:00Z  [[49.0, -122.77], [48.96, -123.12], [48.6, -12...   \n",
       "2  2024-01-03T03:55:00Z  [[32.0976, -96.6626], [31.6289, -95.272], [28....   \n",
       "3  2024-01-03T02:45:00Z                                                NaN   \n",
       "4  2024-01-03T02:45:00Z  [[47.5893, -69.3144], [45.8869, -68.7027], [44...   \n",
       "\n",
       "  min_ft_msl  max_ft_msl  movement_dir_degrees movement_speed_kt      hazard  \\\n",
       "0        NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "1        NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "2        NaN     34000.0                   NaN               NaN  CONVECTIVE   \n",
       "3        NaN         NaN                   NaN               NaN         IFR   \n",
       "4        NaN         NaN                   NaN               NaN   MTN OBSCN   \n",
       "\n",
       "  severity airsigmet_type  \n",
       "0        1         SIGMET  \n",
       "1        1         SIGMET  \n",
       "2   LT-MOD         SIGMET  \n",
       "3        1         AIRMET  \n",
       "4        0         AIRMET  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace with <br> in raw_text\n",
    "# airsigmet_data_df['raw_text'].str.replace(r' \\x07','<br>')\n",
    "# airsigmet_data_df.replace(r' x07','<br>', regex=True)\n",
    "\n",
    "# To convert the points delimiting the areas into something Leaflet-friendly\n",
    "for j in range(len(airsigmet_data_df)):\n",
    "    test=airsigmet_data_df.iloc[j]['lon:lat points']\n",
    "    if  pd.isna(test)!=True:    # Test if the cell is not NaN\n",
    "        test1=test.split(';')\n",
    "        for i in range(len(test1)):\n",
    "            test1[i]=test1[i].split(':')    # Creates list of coordinates\n",
    "            test1[i][0],test1[i][1]=float(test1[i][1]),float(test1[i][0])   # Swap lon:lat to lat:lon\n",
    "        airsigmet_data_df.at[j,'lon:lat points']=test1\n",
    "\n",
    "    # shift cells for missing column\n",
    "    test2=airsigmet_data_df.iloc[j]['airsigmet_type']\n",
    "    if  pd.isna(test2)==True:    # Test if the cell is NaN\n",
    "        airsigmet_data_df.at[j,'airsigmet_type']=airsigmet_data_df.at[j,'severity']\n",
    "        airsigmet_data_df.at[j,'severity']=airsigmet_data_df.at[j,'hazard']\n",
    "        airsigmet_data_df.at[j,'hazard']=airsigmet_data_df.at[j,'movement_speed_kt']\n",
    "        airsigmet_data_df.at[j,'movement_speed_kt']=airsigmet_data_df.at[j,'movement_dir_degrees']\n",
    "        airsigmet_data_df.at[j,'movement_dir_degrees']=airsigmet_data_df.at[j,'max_ft_msl']\n",
    "        airsigmet_data_df.at[j,'max_ft_msl']=airsigmet_data_df.at[j,'min_ft_msl']\n",
    "        airsigmet_data_df.at[j,'min_ft_msl']=\"NaN\"\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "airsigmet_data_df.rename(columns={\"lon:lat points\":\"lat_lon_points\"}, inplace=True) # Update the column name\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# airsigmet_json = json.loads(json.dumps(list(airsigmet_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(airsigmet_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "airsigmet_string=json.dumps(list(airsigmet_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"airsigmet_data.json\")\n",
    "output_path = os.path.join(\"static\", \"airsigmet_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airsigmet_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download headwing and crosswind informations for all runways__ (Not used anymore: to be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with the wind information relative to all runways.\n",
    "# # Will be used to update the makers for all airports.\n",
    "# # There are multiple rows per airport (one per runway).\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT arpt_id, icao_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "# ROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "# ROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "# ROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "# ROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# JOIN apt_rwy_end ON apt_base.site_no = apt_rwy_end.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND arpt_status='O' AND site_type_code='A' AND (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND metar.wind_dir_degrees != 'VRB'\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# rwy_wind_query_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# rwy_wind_string=json.dumps(list(rwy_wind_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"rwy_wind_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rwy_wind_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Retrieve all data to position the circles for all airports and create the popup text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the output of a consolidated query across multiple tables with all information pertinent to an airport.\n",
    "# Will be used to update the makers for all airports.\n",
    "# There are multiple rows per airport (one per runway).\n",
    "# More parameters can be added to complete the info on the popup window.\n",
    "# Will be used to consolidate the information in the popups\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "query=\"\"\"\n",
    "-- Query to get METAR information for each airport as a VIEW\n",
    "DROP VIEW IF EXISTS all_circles_view;\n",
    "CREATE VIEW all_circles_view AS\n",
    "SELECT \n",
    "arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "-- , metar.wind_speed_kt\n",
    "FROM apt_rwy\n",
    "JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "CASE\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Query to get wind information for each runway as a VIEW\n",
    "DROP VIEW IF EXISTS all_rwy_xwind_view;\n",
    "CREATE VIEW all_rwy_xwind_view AS\n",
    "SELECT arpt_id, icao_id, arpt_name, apt_base.tpa, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy.rwy_width, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, apt_rwy_end.right_hand_traffic_pat_flag, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "\tROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "\tROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "\tROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "\tROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "FROM apt_rwy_end\n",
    "FULL JOIN apt_base ON apt_base.site_no = apt_rwy_end.site_no\n",
    "FULL JOIN apt_rwy ON apt_base.site_no = apt_rwy.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND arpt_status='O' AND\n",
    "CASE -- by not have the CASE, we were not providing the rwy length of the airports without METAR\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tAND metar.wind_dir_degrees != 'VRB'\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Merge the two VIEWS\n",
    "SELECT \tall_circles_view.arpt_id, all_circles_view.icao_id, all_circles_view.station_id, all_circles_view.arpt_name, all_circles_view.lat_decimal, all_circles_view.long_decimal, all_circles_view.elev, all_rwy_xwind_view.tpa,\n",
    "\t\tall_circles_view.rwy_id, all_rwy_xwind_view.rwy_end_id, all_rwy_xwind_view.rwy_len, all_rwy_xwind_view.rwy_width, all_rwy_xwind_view.right_hand_traffic_pat_flag,\n",
    "\t\tall_rwy_xwind_view.cross_wind, all_rwy_xwind_view.head_wind, all_rwy_xwind_view.gust_cross_wind, all_rwy_xwind_view.gust_head_wind,\t\t\n",
    "\t\tall_rwy_xwind_view.true_alignment,\n",
    "\t\tall_rwy_xwind_view.wind_dir_degrees, all_rwy_xwind_view.wind_speed_kt, all_rwy_xwind_view.wind_gust_kt,\n",
    "\t\tall_circles_view.flight_category,  all_circles_view.visibility_statute_mi, all_circles_view.cloud_base_ft_agl,\t\t\n",
    "\t\tall_circles_view.observation_time, all_circles_view.raw_text\n",
    "FROM all_circles_view\n",
    "FULL JOIN all_rwy_xwind_view ON all_circles_view.arpt_id = all_rwy_xwind_view.arpt_id\n",
    "AND all_circles_view.rwy_id=all_rwy_xwind_view.rwy_id\n",
    "WHERE all_circles_view.rwy_id NOT LIKE 'H%'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "engine=create_engine(db_url)\n",
    "with engine.begin() as conn:\n",
    "    results=conn.execute(\n",
    "        text(query)\n",
    "    )\n",
    "\n",
    "airport_info_query_raw_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "# airport_info_string=json.dumps(list(airport_info_query_raw_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_info_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport_info_query_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
       "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
       "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
       "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
       "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
       "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
       "       'raw_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_info_query_raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View length: 13621\n"
     ]
    }
   ],
   "source": [
    "# Consolidation of the database with only one row per airport regardless of the number of runways\n",
    "\n",
    "airport_info_query_df=pd.DataFrame(columns=['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
    "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
    "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
    "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
    "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
    "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
    "       'raw_text'])\n",
    "\n",
    "airport_info_query_df[\"popup_text\"]=np.nan\n",
    "\n",
    "first_row=True\n",
    "first_rwy=True\n",
    "\n",
    "a=len(airport_info_query_raw_df)\n",
    "print(f\"View length: {a}\")\n",
    "for i in range (a):\n",
    "    if first_row:\n",
    "       k=i\n",
    "       airport_info_query_df.loc[airport_info_query_raw_df.index[i]] = airport_info_query_raw_df.iloc[i]\n",
    "       popup_text=\"\"\"<div class=\"arpt_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_id\"]+'</div>'\n",
    "\n",
    "       if airport_info_query_raw_df.iloc[i][\"icao_id\"] is not None:\n",
    "           popup_text=popup_text+\"\"\"<div class=\"icao_id\"> / \"\"\"+airport_info_query_raw_df.iloc[i][\"icao_id\"]+'</div>'\n",
    "\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"arpt_name\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_name\"]+'</div>'\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"elev\">Airport Elevation: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"tpa\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+int(airport_info_query_raw_df.iloc[i][\"tpa\"])))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "       else:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA (estimated): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+1000))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "             \n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"visibility_statute_mi\">Airport visibility: \"\"\"+airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"]+' (SM)</div>'\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"cloud_base_ft_agl\">Airport ceiling: \"\"\"+str(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])+' (ft AGL)</div>'\n",
    "\n",
    "       first_row=False\n",
    "\n",
    "    if first_rwy:\n",
    "        popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_id\"> Runway \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_id\"]+' </div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_len\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_len\"> Runway length: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_len\"]))+' (ft)</div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_width\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_width\"> Runway width: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_width\"]))+' (ft)</div>'\n",
    "        first_rwy=False\n",
    "\n",
    "    if (pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False & pd.isna(airport_info_query_raw_df.iloc[i][\"true_alignment\"])==False) | (airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y'):\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_end_id\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_end_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_end_id\"]+' :</div>'\n",
    "            if airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y':\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"RP\"> RP </div>\"\"\"\n",
    "\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"cross_wind\">Crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"head_wind\">Headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_cross_wind\">Gust crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_head_wind\">Gust headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "\n",
    "    if i<a-1:\n",
    "        if airport_info_query_raw_df.iloc[i+1][\"arpt_id\"]!=airport_info_query_raw_df.iloc[i][\"arpt_id\"]:\n",
    "            if pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False:\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"raw_text\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"raw_text\"]+'</div>'\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"observation_time\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"observation_time\"]+'</div>'\n",
    "            else:\n",
    "                popup_text=popup_text+'<br> <div class=\"raw_text\">No weather information</div>'\n",
    "\n",
    "            airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "            # print(f\"k={k}, i={i}\")\n",
    "            # print(popup_text)\n",
    "            first_row=True\n",
    "            first_rwy=True\n",
    "        elif airport_info_query_raw_df.iloc[i+1][\"rwy_id\"]!=airport_info_query_raw_df.iloc[i][\"rwy_id\"]:\n",
    "            first_rwy=True\n",
    "\n",
    "    if i==a-1:\n",
    "        airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "airport_info_string=json.dumps(list(airport_info_query_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "output_path = os.path.join(\"static\", \"airport_info_full_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airport_info_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block\n",
    "        \n",
    "\n",
    "\n",
    "# airport_info_query_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport_info_query_df[airport_info_query_df['arpt_id']=='BLU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
