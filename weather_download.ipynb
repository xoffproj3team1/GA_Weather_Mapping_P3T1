{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv    # from Karen's or Khaled's code\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import select      # Not used\n",
    "import psycopg2\n",
    "import csv   # Not used\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "\n",
    "# import gzip    # Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_metar_gz=\"https://aviationweather.gov/data/cache/metars.cache.csv.gz\"\n",
    "url_TAF_gz=\"https://aviationweather.gov/data/cache/tafs.cache.csv.gz\"\n",
    "url_airsigmets_gz=\"https://aviationweather.gov/data/cache/airsigmets.cache.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve METAR data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>station_id</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>dewpoint_c</th>\n",
       "      <th>wind_dir_degrees</th>\n",
       "      <th>wind_speed_kt</th>\n",
       "      <th>wind_gust_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>maxT24hr_c</th>\n",
       "      <th>minT24hr_c</th>\n",
       "      <th>precip_in</th>\n",
       "      <th>pcp3hr_in</th>\n",
       "      <th>pcp6hr_in</th>\n",
       "      <th>pcp24hr_in</th>\n",
       "      <th>snow_in</th>\n",
       "      <th>vert_vis_ft</th>\n",
       "      <th>metar_type</th>\n",
       "      <th>elevation_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CYIN 020118Z AUTO 13008KT 9SM FEW009 BKN110 M0...</td>\n",
       "      <td>CYIN</td>\n",
       "      <td>2024-01-02T01:18:00Z</td>\n",
       "      <td>51.2650</td>\n",
       "      <td>-121.6810</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>130</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>1127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CYGL 020118Z 23011G17KT 4SM -FZDZ BR OVC008 M0...</td>\n",
       "      <td>CYGL</td>\n",
       "      <td>2024-01-02T01:18:00Z</td>\n",
       "      <td>53.6250</td>\n",
       "      <td>-77.7000</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>230</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KGAI 020117Z AUTO 31006KT 10SM UP OVC028 02/01...</td>\n",
       "      <td>KGAI</td>\n",
       "      <td>2024-01-02T01:17:00Z</td>\n",
       "      <td>39.1696</td>\n",
       "      <td>-77.1653</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>310</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CYRV 020117Z AUTO 00000KT 6SM BR OVC011 02/02 ...</td>\n",
       "      <td>CYRV</td>\n",
       "      <td>2024-01-02T01:17:00Z</td>\n",
       "      <td>50.9580</td>\n",
       "      <td>-118.1760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YFRT 020116Z AUTO 14021G31KT 9999 // NCD 24/13...</td>\n",
       "      <td>YFRT</td>\n",
       "      <td>2024-01-02T01:16:00Z</td>\n",
       "      <td>-30.8480</td>\n",
       "      <td>128.1140</td>\n",
       "      <td>24.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>140</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text station_id  \\\n",
       "0  CYIN 020118Z AUTO 13008KT 9SM FEW009 BKN110 M0...       CYIN   \n",
       "1  CYGL 020118Z 23011G17KT 4SM -FZDZ BR OVC008 M0...       CYGL   \n",
       "2  KGAI 020117Z AUTO 31006KT 10SM UP OVC028 02/01...       KGAI   \n",
       "3  CYRV 020117Z AUTO 00000KT 6SM BR OVC011 02/02 ...       CYRV   \n",
       "4  YFRT 020116Z AUTO 14021G31KT 9999 // NCD 24/13...       YFRT   \n",
       "\n",
       "       observation_time  latitude  longitude  temp_c  dewpoint_c  \\\n",
       "0  2024-01-02T01:18:00Z   51.2650  -121.6810    -2.0        -3.0   \n",
       "1  2024-01-02T01:18:00Z   53.6250   -77.7000    -6.0        -7.0   \n",
       "2  2024-01-02T01:17:00Z   39.1696   -77.1653     2.0         1.0   \n",
       "3  2024-01-02T01:17:00Z   50.9580  -118.1760     2.0         2.0   \n",
       "4  2024-01-02T01:16:00Z  -30.8480   128.1140    24.0        13.0   \n",
       "\n",
       "  wind_dir_degrees  wind_speed_kt  wind_gust_kt  ... maxT24hr_c  minT24hr_c  \\\n",
       "0              130            8.0           NaN  ...        NaN         NaN   \n",
       "1              230           11.0          17.0  ...        NaN         NaN   \n",
       "2              310            6.0           NaN  ...        NaN         NaN   \n",
       "3                0            0.0           NaN  ...        NaN         NaN   \n",
       "4              140           21.0          31.0  ...        NaN         NaN   \n",
       "\n",
       "   precip_in pcp3hr_in pcp6hr_in pcp24hr_in snow_in vert_vis_ft metar_type  \\\n",
       "0        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "1        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "2      0.005       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "3        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "4        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "\n",
       "  elevation_m  \n",
       "0      1127.0  \n",
       "1       192.0  \n",
       "2       151.0  \n",
       "3       456.0  \n",
       "4       159.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to metar\n",
    "metar_data_df = pd.read_csv(url_metar_gz, header=5, compression='gzip')\n",
    "metar_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# metar_json = json.loads(json.dumps(list(metar_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(metar_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(metar_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert some columns to INT\n",
    "# cols=['wind_dir_degrees','wind_speed_kt','wind_gust_kt','cloud_base_ft_agl','cloud_base_ft_agl.2',\\\n",
    "#     'cloud_base_ft_agl.3','vert_vis_ft','elevation_m']\n",
    "# metar_data_df[cols]=metar_data_df[cols].apply(pd.to_numeric, errors='coerce', downcast='integer', axis=1) # Does not appear to convert to INT, but to FLOAT64\n",
    "# metar_data_df[cols]=metar_data_df[cols].astype(int)   # Cannot convert NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "metar_string=json.dumps(list(metar_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"metar_data.json\")  # To be removed if logic.js cannot read from Resources\n",
    "output_path = os.path.join(\"\", \"metar_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(metar_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the dataframe as a csv file for future import to database (not needed anymore)\n",
    "# output_path2 = os.path.join(\"\", \"metar_data.csv\")\n",
    "# metar_data_df.to_csv(output_path2, index=False)\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To refresh the metar table in the Render database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the metar table\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DELETE FROM metar;\")    # Deletes all the rows but keep the table\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repopulate the empty table from a json file\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"set search_path to public\") # https://dba.stackexchange.com/questions/268365/using-python-to-insert-json-into-postgresql\n",
    "\n",
    "with open('metar_data.json') as file:\n",
    "    data = file.read()\n",
    "\n",
    "query_sql = \"\"\"\n",
    "INSERT INTO metar SELECT * FROM\n",
    "json_populate_recordset(NULL::metar, %s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_sql, (data,))\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download a new json file made of the joining of airport data and weather data__ (not used anymore: To be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with all the active public airport with or without weather information.\n",
    "# # Will be used to populate the makers that do not have METAR information.\n",
    "# # There is only one row per airport so only one runway is listed even if the airport as more.\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "# # query=\"\"\"\n",
    "# #     SELECT DISTINCT ON (arpt_id)\n",
    "# # \tarpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, long_decimal, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text\n",
    "# #     FROM apt_rwy\n",
    "# #     JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# #     FULL JOIN metar ON metar.station_id = apt_base.icao_id\n",
    "# #     WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O';\n",
    "# #     \"\"\"\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT DISTINCT ON (arpt_id)\n",
    "#     arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "# CASE\n",
    "# \tWHEN metar.station_id IS NOT NULL\n",
    "# \tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "# \tWHEN metar.station_id IS NULL\n",
    "# \tTHEN site_type_code='A'\n",
    "# END\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# arpt_weather_query_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save the df as a CSV file. Might not be needed if we only use JSON    TO BE REMOVED?\n",
    "# # arpt_weather_query_df.to_csv (r'airport_weather_data.csv', index = False) # place 'r' before the path name\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# arpt_weather_string=json.dumps(list(arpt_weather_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_weather_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(arpt_weather_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arpt_weather_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(arpt_weather_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve TAF data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch, load, and decompress the data relative to TAF  (working but not used for now)\n",
    "# taf_data_df = pd.read_csv(url_TAF_gz, header=5,index_col=False, compression='gzip',dtype='str',low_memory=False)\n",
    "# taf_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format  (working but not used for now)\n",
    "# taf_json = json.loads(json.dumps(list(taf_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(taf_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the dataframe to a dictionary then to a JSON string  (working but not used for now)\n",
    "# taf_string=json.dumps(list(taf_data_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"taf_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(taf_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve AIRMET and SIGMET polygons data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lon:lat points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS32 KKCI 020055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-02T00:55:00Z</td>\n",
       "      <td>2024-01-02T02:55:00Z</td>\n",
       "      <td>-107:49;-107:31.79;-106.52:31.78;-106.48:31.75...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS31 KKCI 020055 \u0007SIGE  \u0007CONVECTIVE SIGMET 1...</td>\n",
       "      <td>2024-01-02T00:55:00Z</td>\n",
       "      <td>2024-01-02T02:55:00Z</td>\n",
       "      <td>-72.6727:36.1988;-72.6138:34.9867;-74.5683:33....</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS33 KKCI 020055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-02T00:55:00Z</td>\n",
       "      <td>2024-01-02T02:55:00Z</td>\n",
       "      <td>-122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAUS43 KKCI 012045 \u0007CHIT WA 012045 \u0007AIRMET TAN...</td>\n",
       "      <td>2024-01-01T20:45:00Z</td>\n",
       "      <td>2024-01-02T02:45:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TURB</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAUS42 KKCI 012045 \u0007MIAT WA 012045 \u0007AIRMET TAN...</td>\n",
       "      <td>2024-01-01T20:45:00Z</td>\n",
       "      <td>2024-01-02T03:00:00Z</td>\n",
       "      <td>-79.547:36.6354;-77.3167:35.863;-76.18:35.0822...</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TURB</td>\n",
       "      <td>MOD</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS32 KKCI 020055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-02T00:55:00Z   \n",
       "1  WSUS31 KKCI 020055 \u0007SIGE  \u0007CONVECTIVE SIGMET 1...  2024-01-02T00:55:00Z   \n",
       "2  WSUS33 KKCI 020055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....  2024-01-02T00:55:00Z   \n",
       "3  WAUS43 KKCI 012045 \u0007CHIT WA 012045 \u0007AIRMET TAN...  2024-01-01T20:45:00Z   \n",
       "4  WAUS42 KKCI 012045 \u0007MIAT WA 012045 \u0007AIRMET TAN...  2024-01-01T20:45:00Z   \n",
       "\n",
       "          valid_time_to                                     lon:lat points  \\\n",
       "0  2024-01-02T02:55:00Z  -107:49;-107:31.79;-106.52:31.78;-106.48:31.75...   \n",
       "1  2024-01-02T02:55:00Z  -72.6727:36.1988;-72.6138:34.9867;-74.5683:33....   \n",
       "2  2024-01-02T02:55:00Z  -122.77:49;-123.12:48.96;-123.02:48.6;-123.16:...   \n",
       "3  2024-01-02T02:45:00Z                                                NaN   \n",
       "4  2024-01-02T03:00:00Z  -79.547:36.6354;-77.3167:35.863;-76.18:35.0822...   \n",
       "\n",
       "   min_ft_msl  max_ft_msl  movement_dir_degrees movement_speed_kt      hazard  \\\n",
       "0         NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "1     25000.0         NaN                   NaN        CONVECTIVE      LT-MOD   \n",
       "2         NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "3         NaN         NaN                   NaN               NaN        TURB   \n",
       "4     16000.0     35000.0                   NaN               NaN        TURB   \n",
       "\n",
       "  severity airsigmet_type  \n",
       "0        1         SIGMET  \n",
       "1   SIGMET            NaN  \n",
       "2        1         SIGMET  \n",
       "3        1         AIRMET  \n",
       "4      MOD         AIRMET  "
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to Airmet and Sigmet\n",
    "airsigmet_data_df = pd.read_csv(url_airsigmets_gz, header=5, compression='gzip', encoding='utf-8')\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lat_lon_points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS32 KKCI 020055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-02T00:55:00Z</td>\n",
       "      <td>2024-01-02T02:55:00Z</td>\n",
       "      <td>[[49.0, -107.0], [31.79, -107.0], [31.78, -106...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS31 KKCI 020055 \u0007SIGE  \u0007CONVECTIVE SIGMET 1...</td>\n",
       "      <td>2024-01-02T00:55:00Z</td>\n",
       "      <td>2024-01-02T02:55:00Z</td>\n",
       "      <td>[[36.1988, -72.6727], [34.9867, -72.6138], [33...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS33 KKCI 020055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-02T00:55:00Z</td>\n",
       "      <td>2024-01-02T02:55:00Z</td>\n",
       "      <td>[[49.0, -122.77], [48.96, -123.12], [48.6, -12...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAUS43 KKCI 012045 \u0007CHIT WA 012045 \u0007AIRMET TAN...</td>\n",
       "      <td>2024-01-01T20:45:00Z</td>\n",
       "      <td>2024-01-02T02:45:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TURB</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAUS42 KKCI 012045 \u0007MIAT WA 012045 \u0007AIRMET TAN...</td>\n",
       "      <td>2024-01-01T20:45:00Z</td>\n",
       "      <td>2024-01-02T03:00:00Z</td>\n",
       "      <td>[[36.6354, -79.547], [35.863, -77.3167], [35.0...</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TURB</td>\n",
       "      <td>MOD</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS32 KKCI 020055 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-02T00:55:00Z   \n",
       "1  WSUS31 KKCI 020055 \u0007SIGE  \u0007CONVECTIVE SIGMET 1...  2024-01-02T00:55:00Z   \n",
       "2  WSUS33 KKCI 020055 \u0007SIGW  \u0007CONVECTIVE SIGMET.....  2024-01-02T00:55:00Z   \n",
       "3  WAUS43 KKCI 012045 \u0007CHIT WA 012045 \u0007AIRMET TAN...  2024-01-01T20:45:00Z   \n",
       "4  WAUS42 KKCI 012045 \u0007MIAT WA 012045 \u0007AIRMET TAN...  2024-01-01T20:45:00Z   \n",
       "\n",
       "          valid_time_to                                     lat_lon_points  \\\n",
       "0  2024-01-02T02:55:00Z  [[49.0, -107.0], [31.79, -107.0], [31.78, -106...   \n",
       "1  2024-01-02T02:55:00Z  [[36.1988, -72.6727], [34.9867, -72.6138], [33...   \n",
       "2  2024-01-02T02:55:00Z  [[49.0, -122.77], [48.96, -123.12], [48.6, -12...   \n",
       "3  2024-01-02T02:45:00Z                                                NaN   \n",
       "4  2024-01-02T03:00:00Z  [[36.6354, -79.547], [35.863, -77.3167], [35.0...   \n",
       "\n",
       "  min_ft_msl  max_ft_msl  movement_dir_degrees movement_speed_kt      hazard  \\\n",
       "0        NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "1        NaN     25000.0                   NaN               NaN  CONVECTIVE   \n",
       "2        NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "3        NaN         NaN                   NaN               NaN        TURB   \n",
       "4    16000.0     35000.0                   NaN               NaN        TURB   \n",
       "\n",
       "  severity airsigmet_type  \n",
       "0        1         SIGMET  \n",
       "1   LT-MOD         SIGMET  \n",
       "2        1         SIGMET  \n",
       "3        1         AIRMET  \n",
       "4      MOD         AIRMET  "
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace with <br> in raw_text\n",
    "# airsigmet_data_df['raw_text'].str.replace(r' \\x07','<br>')\n",
    "# airsigmet_data_df.replace(r' x07','<br>', regex=True)\n",
    "\n",
    "# To convert the points delimiting the areas into something Leaflet-friendly\n",
    "for j in range(len(airsigmet_data_df)):\n",
    "    test=airsigmet_data_df.iloc[j]['lon:lat points']\n",
    "    if  pd.isna(test)!=True:    # Test if the cell is not NaN\n",
    "        test1=test.split(';')\n",
    "        for i in range(len(test1)):\n",
    "            test1[i]=test1[i].split(':')    # Creates list of coordinates\n",
    "            test1[i][0],test1[i][1]=float(test1[i][1]),float(test1[i][0])   # Swap lon:lat to lat:lon\n",
    "        airsigmet_data_df.at[j,'lon:lat points']=test1\n",
    "\n",
    "    # shift cells for missing column\n",
    "    test2=airsigmet_data_df.iloc[j]['airsigmet_type']\n",
    "    if  pd.isna(test2)==True:    # Test if the cell is NaN\n",
    "        airsigmet_data_df.at[j,'airsigmet_type']=airsigmet_data_df.at[j,'severity']\n",
    "        airsigmet_data_df.at[j,'severity']=airsigmet_data_df.at[j,'hazard']\n",
    "        airsigmet_data_df.at[j,'hazard']=airsigmet_data_df.at[j,'movement_speed_kt']\n",
    "        airsigmet_data_df.at[j,'movement_speed_kt']=airsigmet_data_df.at[j,'movement_dir_degrees']\n",
    "        airsigmet_data_df.at[j,'movement_dir_degrees']=airsigmet_data_df.at[j,'max_ft_msl']\n",
    "        airsigmet_data_df.at[j,'max_ft_msl']=airsigmet_data_df.at[j,'min_ft_msl']\n",
    "        airsigmet_data_df.at[j,'min_ft_msl']=\"NaN\"\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "airsigmet_data_df.rename(columns={\"lon:lat points\":\"lat_lon_points\"}, inplace=True) # Update the column name\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# airsigmet_json = json.loads(json.dumps(list(airsigmet_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(airsigmet_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "airsigmet_string=json.dumps(list(airsigmet_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"airsigmet_data.json\")\n",
    "output_path = os.path.join(\"\", \"airsigmet_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airsigmet_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download headwing and crosswind informations for all runways__ (Not used anymore: to be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with the wind information relative to all runways.\n",
    "# # Will be used to update the makers for all airports.\n",
    "# # There are multiple rows per airport (one per runway).\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT arpt_id, icao_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "# ROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "# ROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "# ROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "# ROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# JOIN apt_rwy_end ON apt_base.site_no = apt_rwy_end.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND arpt_status='O' AND site_type_code='A' AND (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND metar.wind_dir_degrees != 'VRB'\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# rwy_wind_query_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# rwy_wind_string=json.dumps(list(rwy_wind_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"rwy_wind_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rwy_wind_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Retrieve all data to position the circles for all airports and create the popup text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the output of a consolidated query across multiple tables with all information pertinent to an airport.\n",
    "# Will be used to update the makers for all airports.\n",
    "# There are multiple rows per airport (one per runway).\n",
    "# More parameters can be added to complete the info on the popup window.\n",
    "# Will be used to consolidate the information in the popups\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "query=\"\"\"\n",
    "-- Query to get METAR information for each airport as a VIEW\n",
    "DROP VIEW IF EXISTS all_circles_view;\n",
    "CREATE VIEW all_circles_view AS\n",
    "SELECT \n",
    "arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "-- , metar.wind_speed_kt\n",
    "FROM apt_rwy\n",
    "JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "CASE\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Query to get wind information for each runway as a VIEW\n",
    "DROP VIEW IF EXISTS all_rwy_xwind_view;\n",
    "CREATE VIEW all_rwy_xwind_view AS\n",
    "SELECT arpt_id, icao_id, arpt_name, apt_base.tpa, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy.rwy_width, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, apt_rwy_end.right_hand_traffic_pat_flag, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "\tROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "\tROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "\tROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "\tROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "FROM apt_rwy_end\n",
    "FULL JOIN apt_base ON apt_base.site_no = apt_rwy_end.site_no\n",
    "FULL JOIN apt_rwy ON apt_base.site_no = apt_rwy.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND arpt_status='O' AND\n",
    "CASE -- by not have the CASE, we were not providing the rwy length of the airports without METAR\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tAND metar.wind_dir_degrees != 'VRB'\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Merge the two VIEWS\n",
    "SELECT \tall_circles_view.arpt_id, all_circles_view.icao_id, all_circles_view.station_id, all_circles_view.arpt_name, all_circles_view.lat_decimal, all_circles_view.long_decimal, all_circles_view.elev, all_rwy_xwind_view.tpa,\n",
    "\t\tall_circles_view.rwy_id, all_rwy_xwind_view.rwy_end_id, all_rwy_xwind_view.rwy_len, all_rwy_xwind_view.rwy_width, all_rwy_xwind_view.right_hand_traffic_pat_flag,\n",
    "\t\tall_rwy_xwind_view.cross_wind, all_rwy_xwind_view.head_wind, all_rwy_xwind_view.gust_cross_wind, all_rwy_xwind_view.gust_head_wind,\t\t\n",
    "\t\tall_rwy_xwind_view.true_alignment,\n",
    "\t\tall_rwy_xwind_view.wind_dir_degrees, all_rwy_xwind_view.wind_speed_kt, all_rwy_xwind_view.wind_gust_kt,\n",
    "\t\tall_circles_view.flight_category,  all_circles_view.visibility_statute_mi, all_circles_view.cloud_base_ft_agl,\t\t\n",
    "\t\tall_circles_view.observation_time, all_circles_view.raw_text\n",
    "FROM all_circles_view\n",
    "FULL JOIN all_rwy_xwind_view ON all_circles_view.arpt_id = all_rwy_xwind_view.arpt_id\n",
    "AND all_circles_view.rwy_id=all_rwy_xwind_view.rwy_id\n",
    "WHERE all_circles_view.rwy_id NOT LIKE 'H%'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "engine=create_engine(db_url)\n",
    "with engine.begin() as conn:\n",
    "    results=conn.execute(\n",
    "        text(query)\n",
    "    )\n",
    "\n",
    "airport_info_query_raw_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "# airport_info_string=json.dumps(list(airport_info_query_raw_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_info_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport_info_query_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
       "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
       "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
       "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
       "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
       "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
       "       'raw_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_info_query_raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View length: 13616\n"
     ]
    }
   ],
   "source": [
    "# Consolidation of the database with only one row per airport regardless of the number of runways\n",
    "\n",
    "airport_info_query_df=pd.DataFrame(columns=['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
    "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
    "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
    "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
    "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
    "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
    "       'raw_text'])\n",
    "\n",
    "airport_info_query_df[\"popup_text\"]=np.nan\n",
    "\n",
    "first_row=True\n",
    "first_rwy=True\n",
    "\n",
    "a=len(airport_info_query_raw_df)\n",
    "print(f\"View length: {a}\")\n",
    "for i in range (a):\n",
    "    if first_row:\n",
    "       k=i\n",
    "       airport_info_query_df.loc[airport_info_query_raw_df.index[i]] = airport_info_query_raw_df.iloc[i]\n",
    "       popup_text=\"\"\"<div class=\"arpt_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_id\"]+'</div>'\n",
    "\n",
    "       if airport_info_query_raw_df.iloc[i][\"icao_id\"] is not None:\n",
    "           popup_text=popup_text+\"\"\"<div class=\"icao_id\"> / \"\"\"+airport_info_query_raw_df.iloc[i][\"icao_id\"]+'</div>'\n",
    "\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"arpt_name\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_name\"]+'</div>'\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"elev\">Airport Elevation: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"tpa\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+int(airport_info_query_raw_df.iloc[i][\"tpa\"])))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "       else:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA (estimated): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+1000))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "             \n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"visibility_statute_mi\">Airport visibility: \"\"\"+airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"]+' (SM)</div>'\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"cloud_base_ft_agl\">Airport ceiling: \"\"\"+str(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])+' (ft AGL)</div>'\n",
    "\n",
    "       first_row=False\n",
    "\n",
    "    if first_rwy:\n",
    "        popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_id\"> Runway \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_id\"]+' </div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_len\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_len\"> Runway length: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_len\"]))+' (ft)</div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_width\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_width\"> Runway width: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_width\"]))+' (ft)</div>'\n",
    "        first_rwy=False\n",
    "\n",
    "    if (pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False & pd.isna(airport_info_query_raw_df.iloc[i][\"true_alignment\"])==False) | (airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y'):\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_end_id\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_end_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_end_id\"]+' :</div>'\n",
    "            if airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y':\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"RP\"> RP </div>\"\"\"\n",
    "\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"cross_wind\">Crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"head_wind\">Headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_cross_wind\">Gust crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_head_wind\">Gust headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "\n",
    "    if i<a-1:\n",
    "        if airport_info_query_raw_df.iloc[i+1][\"arpt_id\"]!=airport_info_query_raw_df.iloc[i][\"arpt_id\"]:\n",
    "            if pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False:\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"raw_text\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"raw_text\"]+'</div>'\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"observation_time\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"observation_time\"]+'</div>'\n",
    "            else:\n",
    "                popup_text=popup_text+'<br> <div class=\"raw_text\">No weather information</div>'\n",
    "\n",
    "            airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "            # print(f\"k={k}, i={i}\")\n",
    "            # print(popup_text)\n",
    "            first_row=True\n",
    "            first_rwy=True\n",
    "        elif airport_info_query_raw_df.iloc[i+1][\"rwy_id\"]!=airport_info_query_raw_df.iloc[i][\"rwy_id\"]:\n",
    "            first_rwy=True\n",
    "\n",
    "    if i==a-1:\n",
    "        airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "airport_info_string=json.dumps(list(airport_info_query_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "output_path = os.path.join(\"\", \"airport_info_full_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airport_info_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block\n",
    "        \n",
    "\n",
    "\n",
    "# airport_info_query_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport_info_query_df[airport_info_query_df['arpt_id']=='BLU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
