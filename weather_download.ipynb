{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv    # from Karen's or Khaled's code\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import select      # Not used\n",
    "import psycopg2\n",
    "import csv   # Not used\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json\n",
    "import logging\n",
    "import boto3        # AWS SDK for Python\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "# import gzip    # Not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_metar_gz=\"https://aviationweather.gov/data/cache/metars.cache.csv.gz\"\n",
    "url_TAF_gz=\"https://aviationweather.gov/data/cache/tafs.cache.csv.gz\"\n",
    "url_airsigmets_gz=\"https://aviationweather.gov/data/cache/airsigmets.cache.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve METAR data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>station_id</th>\n",
       "      <th>observation_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>dewpoint_c</th>\n",
       "      <th>wind_dir_degrees</th>\n",
       "      <th>wind_speed_kt</th>\n",
       "      <th>wind_gust_kt</th>\n",
       "      <th>...</th>\n",
       "      <th>maxT24hr_c</th>\n",
       "      <th>minT24hr_c</th>\n",
       "      <th>precip_in</th>\n",
       "      <th>pcp3hr_in</th>\n",
       "      <th>pcp6hr_in</th>\n",
       "      <th>pcp24hr_in</th>\n",
       "      <th>snow_in</th>\n",
       "      <th>vert_vis_ft</th>\n",
       "      <th>metar_type</th>\n",
       "      <th>elevation_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CYKL 020732Z AUTO 24016G22KT 6SM -SN FEW016 M1...</td>\n",
       "      <td>CYKL</td>\n",
       "      <td>2024-01-02T07:32:00Z</td>\n",
       "      <td>54.8030</td>\n",
       "      <td>-66.8040</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>240</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>507.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KRHP 020731Z AUTO 00000KT 10SM CLR M03/M06 A30...</td>\n",
       "      <td>KRHP</td>\n",
       "      <td>2024-01-02T07:31:00Z</td>\n",
       "      <td>35.1939</td>\n",
       "      <td>-83.8618</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KJKJ 020731Z AUTO 28009KT 10SM CLR M03/M06 A29...</td>\n",
       "      <td>KJKJ</td>\n",
       "      <td>2024-01-02T07:31:00Z</td>\n",
       "      <td>46.8404</td>\n",
       "      <td>-96.6545</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>280</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>METAR</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CYYN 020731Z AUTO 22009KT 3/8SM SN FEW001 M08/...</td>\n",
       "      <td>CYYN</td>\n",
       "      <td>2024-01-02T07:31:00Z</td>\n",
       "      <td>50.2920</td>\n",
       "      <td>-107.6910</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>220</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYXS 020731Z AUTO 01005KT 1/2SM FZFG SCT001 M0...</td>\n",
       "      <td>CYXS</td>\n",
       "      <td>2024-01-02T07:31:00Z</td>\n",
       "      <td>53.8840</td>\n",
       "      <td>-122.6770</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECI</td>\n",
       "      <td>685.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text station_id  \\\n",
       "0  CYKL 020732Z AUTO 24016G22KT 6SM -SN FEW016 M1...       CYKL   \n",
       "1  KRHP 020731Z AUTO 00000KT 10SM CLR M03/M06 A30...       KRHP   \n",
       "2  KJKJ 020731Z AUTO 28009KT 10SM CLR M03/M06 A29...       KJKJ   \n",
       "3  CYYN 020731Z AUTO 22009KT 3/8SM SN FEW001 M08/...       CYYN   \n",
       "4  CYXS 020731Z AUTO 01005KT 1/2SM FZFG SCT001 M0...       CYXS   \n",
       "\n",
       "       observation_time  latitude  longitude  temp_c  dewpoint_c  \\\n",
       "0  2024-01-02T07:32:00Z   54.8030   -66.8040   -12.0       -14.0   \n",
       "1  2024-01-02T07:31:00Z   35.1939   -83.8618    -3.5        -6.4   \n",
       "2  2024-01-02T07:31:00Z   46.8404   -96.6545    -3.0        -6.0   \n",
       "3  2024-01-02T07:31:00Z   50.2920  -107.6910    -8.0       -10.0   \n",
       "4  2024-01-02T07:31:00Z   53.8840  -122.6770    -6.0        -7.0   \n",
       "\n",
       "  wind_dir_degrees  wind_speed_kt  wind_gust_kt  ... maxT24hr_c  minT24hr_c  \\\n",
       "0              240           16.0          22.0  ...        NaN         NaN   \n",
       "1                0            0.0           NaN  ...        NaN         NaN   \n",
       "2              280            9.0           NaN  ...        NaN         NaN   \n",
       "3              220            9.0           NaN  ...        NaN         NaN   \n",
       "4               10            5.0           NaN  ...        NaN         NaN   \n",
       "\n",
       "   precip_in pcp3hr_in pcp6hr_in pcp24hr_in snow_in vert_vis_ft metar_type  \\\n",
       "0        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "1        NaN       NaN       NaN        NaN     NaN         NaN      METAR   \n",
       "2        NaN       NaN       NaN        NaN     NaN         NaN      METAR   \n",
       "3        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "4        NaN       NaN       NaN        NaN     NaN         NaN      SPECI   \n",
       "\n",
       "  elevation_m  \n",
       "0       507.0  \n",
       "1       515.0  \n",
       "2       280.0  \n",
       "3       814.0  \n",
       "4       685.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to metar\n",
    "metar_data_df = pd.read_csv(url_metar_gz, header=5, compression='gzip')\n",
    "metar_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# metar_json = json.loads(json.dumps(list(metar_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(metar_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(metar_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert some columns to INT\n",
    "# cols=['wind_dir_degrees','wind_speed_kt','wind_gust_kt','cloud_base_ft_agl','cloud_base_ft_agl.2',\\\n",
    "#     'cloud_base_ft_agl.3','vert_vis_ft','elevation_m']\n",
    "# metar_data_df[cols]=metar_data_df[cols].apply(pd.to_numeric, errors='coerce', downcast='integer', axis=1) # Does not appear to convert to INT, but to FLOAT64\n",
    "# metar_data_df[cols]=metar_data_df[cols].astype(int)   # Cannot convert NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metar_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "metar_string=json.dumps(list(metar_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"metar_data.json\")  # To be removed if logic.js cannot read from Resources\n",
    "output_path = os.path.join(\"static\", \"metar_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(metar_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the dataframe as a csv file for future import to database (not needed anymore)\n",
    "# output_path2 = os.path.join(\"\", \"metar_data.csv\")\n",
    "# metar_data_df.to_csv(output_path2, index=False)\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To refresh the metar table in the Render database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the metar table\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(\"DELETE FROM metar;\")    # Deletes all the rows but keep the table\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repopulate the empty table from a json file\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "connection = psycopg2.connect(db_url)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"set search_path to public\") # https://dba.stackexchange.com/questions/268365/using-python-to-insert-json-into-postgresql\n",
    "\n",
    "with open(output_path) as file:\n",
    "    data = file.read()\n",
    "\n",
    "query_sql = \"\"\"\n",
    "INSERT INTO metar SELECT * FROM\n",
    "json_populate_recordset(NULL::metar, %s);\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query_sql, (data,))\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download a new json file made of the joining of airport data and weather data__ (not used anymore: To be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with all the active public airport with or without weather information.\n",
    "# # Will be used to populate the makers that do not have METAR information.\n",
    "# # There is only one row per airport so only one runway is listed even if the airport as more.\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "# # query=\"\"\"\n",
    "# #     SELECT DISTINCT ON (arpt_id)\n",
    "# # \tarpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, long_decimal, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text\n",
    "# #     FROM apt_rwy\n",
    "# #     JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# #     FULL JOIN metar ON metar.station_id = apt_base.icao_id\n",
    "# #     WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O';\n",
    "# #     \"\"\"\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT DISTINCT ON (arpt_id)\n",
    "#     arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.wind_speed_kt, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "# CASE\n",
    "# \tWHEN metar.station_id IS NOT NULL\n",
    "# \tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "# \tWHEN metar.station_id IS NULL\n",
    "# \tTHEN site_type_code='A'\n",
    "# END\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# arpt_weather_query_df = pd.DataFrame(results)\n",
    "\n",
    "# # Save the df as a CSV file. Might not be needed if we only use JSON    TO BE REMOVED?\n",
    "# # arpt_weather_query_df.to_csv (r'airport_weather_data.csv', index = False) # place 'r' before the path name\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# arpt_weather_string=json.dumps(list(arpt_weather_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_weather_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(arpt_weather_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arpt_weather_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(arpt_weather_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve TAF data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch, load, and decompress the data relative to TAF  (working but not used for now)\n",
    "# taf_data_df = pd.read_csv(url_TAF_gz, header=5,index_col=False, compression='gzip',dtype='str',low_memory=False)\n",
    "# taf_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format  (working but not used for now)\n",
    "# taf_json = json.loads(json.dumps(list(taf_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(taf_json, sort_dicts=False)  # the pprint process is slow (10.5sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert the dataframe to a dictionary then to a JSON string  (working but not used for now)\n",
    "# taf_string=json.dumps(list(taf_data_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"taf_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(taf_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To retrieve AIRMET and SIGMET polygons data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lon:lat points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS32 KKCI 020655 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-02T06:55:00Z</td>\n",
       "      <td>2024-01-02T08:55:00Z</td>\n",
       "      <td>-107:49;-107:31.79;-106.52:31.78;-106.48:31.75...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS31 KKCI 020655 \u0007SIGE  \u0007CONVECTIVE SIGMET 6...</td>\n",
       "      <td>2024-01-02T06:55:00Z</td>\n",
       "      <td>2024-01-02T08:55:00Z</td>\n",
       "      <td>-72.4317:37.2917;-73.7076:36.2246;-74.3245:36....</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS33 KKCI 020655 \u0007SIGW  \u0007CONVECTIVE SIGMET 2...</td>\n",
       "      <td>2024-01-02T06:55:00Z</td>\n",
       "      <td>2024-01-02T08:55:00Z</td>\n",
       "      <td>-109.9843:32.0135;-108.1224:31.2;-110.6217:31....</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAUS45 KKCI 020245 \u0007SLCZ WA 020245 \u0007AIRMET ZUL...</td>\n",
       "      <td>2024-01-02T02:45:00Z</td>\n",
       "      <td>2024-01-02T09:00:00Z</td>\n",
       "      <td>-106.2056:35.0385;-104.9021:33.5747;-104.6784:...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "      <td>MOD</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAUS44 KKCI 020245 \u0007DFWZ WA 020245 \u0007AIRMET ZUL...</td>\n",
       "      <td>2024-01-02T02:45:00Z</td>\n",
       "      <td>2024-01-02T08:45:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS32 KKCI 020655 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-02T06:55:00Z   \n",
       "1  WSUS31 KKCI 020655 \u0007SIGE  \u0007CONVECTIVE SIGMET 6...  2024-01-02T06:55:00Z   \n",
       "2  WSUS33 KKCI 020655 \u0007SIGW  \u0007CONVECTIVE SIGMET 2...  2024-01-02T06:55:00Z   \n",
       "3  WAUS45 KKCI 020245 \u0007SLCZ WA 020245 \u0007AIRMET ZUL...  2024-01-02T02:45:00Z   \n",
       "4  WAUS44 KKCI 020245 \u0007DFWZ WA 020245 \u0007AIRMET ZUL...  2024-01-02T02:45:00Z   \n",
       "\n",
       "          valid_time_to                                     lon:lat points  \\\n",
       "0  2024-01-02T08:55:00Z  -107:49;-107:31.79;-106.52:31.78;-106.48:31.75...   \n",
       "1  2024-01-02T08:55:00Z  -72.4317:37.2917;-73.7076:36.2246;-74.3245:36....   \n",
       "2  2024-01-02T08:55:00Z  -109.9843:32.0135;-108.1224:31.2;-110.6217:31....   \n",
       "3  2024-01-02T09:00:00Z  -106.2056:35.0385;-104.9021:33.5747;-104.6784:...   \n",
       "4  2024-01-02T08:45:00Z                                                NaN   \n",
       "\n",
       "   min_ft_msl  max_ft_msl  movement_dir_degrees movement_speed_kt      hazard  \\\n",
       "0         NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "1     21000.0         NaN                   NaN        CONVECTIVE      LT-MOD   \n",
       "2     28000.0         NaN                   NaN        CONVECTIVE      LT-MOD   \n",
       "3     10000.0     19000.0                   NaN               NaN         ICE   \n",
       "4         NaN         NaN                   NaN               NaN         ICE   \n",
       "\n",
       "  severity airsigmet_type  \n",
       "0        1         SIGMET  \n",
       "1   SIGMET            NaN  \n",
       "2   SIGMET            NaN  \n",
       "3      MOD         AIRMET  \n",
       "4        1         AIRMET  "
      ]
     },
     "execution_count": 1105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch, load, and decompress the data relative to Airmet and Sigmet\n",
    "airsigmet_data_df = pd.read_csv(url_airsigmets_gz, header=5, compression='gzip', encoding='utf-8')\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>valid_time_from</th>\n",
       "      <th>valid_time_to</th>\n",
       "      <th>lat_lon_points</th>\n",
       "      <th>min_ft_msl</th>\n",
       "      <th>max_ft_msl</th>\n",
       "      <th>movement_dir_degrees</th>\n",
       "      <th>movement_speed_kt</th>\n",
       "      <th>hazard</th>\n",
       "      <th>severity</th>\n",
       "      <th>airsigmet_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WSUS32 KKCI 020655 \u0007SIGC  \u0007CONVECTIVE SIGMET.....</td>\n",
       "      <td>2024-01-02T06:55:00Z</td>\n",
       "      <td>2024-01-02T08:55:00Z</td>\n",
       "      <td>[[49.0, -107.0], [31.79, -107.0], [31.78, -106...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>1</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WSUS31 KKCI 020655 \u0007SIGE  \u0007CONVECTIVE SIGMET 6...</td>\n",
       "      <td>2024-01-02T06:55:00Z</td>\n",
       "      <td>2024-01-02T08:55:00Z</td>\n",
       "      <td>[[37.2917, -72.4317], [36.2246, -73.7076], [36...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WSUS33 KKCI 020655 \u0007SIGW  \u0007CONVECTIVE SIGMET 2...</td>\n",
       "      <td>2024-01-02T06:55:00Z</td>\n",
       "      <td>2024-01-02T08:55:00Z</td>\n",
       "      <td>[[32.0135, -109.9843], [31.2, -108.1224], [31....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CONVECTIVE</td>\n",
       "      <td>LT-MOD</td>\n",
       "      <td>SIGMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WAUS45 KKCI 020245 \u0007SLCZ WA 020245 \u0007AIRMET ZUL...</td>\n",
       "      <td>2024-01-02T02:45:00Z</td>\n",
       "      <td>2024-01-02T09:00:00Z</td>\n",
       "      <td>[[35.0385, -106.2056], [33.5747, -104.9021], [...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "      <td>MOD</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAUS44 KKCI 020245 \u0007DFWZ WA 020245 \u0007AIRMET ZUL...</td>\n",
       "      <td>2024-01-02T02:45:00Z</td>\n",
       "      <td>2024-01-02T08:45:00Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICE</td>\n",
       "      <td>1</td>\n",
       "      <td>AIRMET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text       valid_time_from  \\\n",
       "0  WSUS32 KKCI 020655 \u0007SIGC  \u0007CONVECTIVE SIGMET.....  2024-01-02T06:55:00Z   \n",
       "1  WSUS31 KKCI 020655 \u0007SIGE  \u0007CONVECTIVE SIGMET 6...  2024-01-02T06:55:00Z   \n",
       "2  WSUS33 KKCI 020655 \u0007SIGW  \u0007CONVECTIVE SIGMET 2...  2024-01-02T06:55:00Z   \n",
       "3  WAUS45 KKCI 020245 \u0007SLCZ WA 020245 \u0007AIRMET ZUL...  2024-01-02T02:45:00Z   \n",
       "4  WAUS44 KKCI 020245 \u0007DFWZ WA 020245 \u0007AIRMET ZUL...  2024-01-02T02:45:00Z   \n",
       "\n",
       "          valid_time_to                                     lat_lon_points  \\\n",
       "0  2024-01-02T08:55:00Z  [[49.0, -107.0], [31.79, -107.0], [31.78, -106...   \n",
       "1  2024-01-02T08:55:00Z  [[37.2917, -72.4317], [36.2246, -73.7076], [36...   \n",
       "2  2024-01-02T08:55:00Z  [[32.0135, -109.9843], [31.2, -108.1224], [31....   \n",
       "3  2024-01-02T09:00:00Z  [[35.0385, -106.2056], [33.5747, -104.9021], [...   \n",
       "4  2024-01-02T08:45:00Z                                                NaN   \n",
       "\n",
       "  min_ft_msl  max_ft_msl  movement_dir_degrees movement_speed_kt      hazard  \\\n",
       "0        NaN         NaN                   NaN               NaN  CONVECTIVE   \n",
       "1        NaN     21000.0                   NaN               NaN  CONVECTIVE   \n",
       "2        NaN     28000.0                   NaN               NaN  CONVECTIVE   \n",
       "3    10000.0     19000.0                   NaN               NaN         ICE   \n",
       "4        NaN         NaN                   NaN               NaN         ICE   \n",
       "\n",
       "  severity airsigmet_type  \n",
       "0        1         SIGMET  \n",
       "1   LT-MOD         SIGMET  \n",
       "2   LT-MOD         SIGMET  \n",
       "3      MOD         AIRMET  \n",
       "4        1         AIRMET  "
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace with <br> in raw_text\n",
    "airsigmet_data_df[\"raw_text\"] = airsigmet_data_df[\"raw_text\"].replace(r'\\x07','<br>', regex=True)   # Used to replace \\n that does not get decompressed as utf-8 and was converted as \\x07\n",
    "\n",
    "# To convert the points delimiting the areas into something Leaflet-friendly\n",
    "for j in range(len(airsigmet_data_df)):\n",
    "    test=airsigmet_data_df.iloc[j]['lon:lat points']\n",
    "    if  pd.isna(test)!=True:    # Test if the cell is not NaN\n",
    "        test1=test.split(';')\n",
    "        for i in range(len(test1)):\n",
    "            test1[i]=test1[i].split(':')    # Creates list of coordinates\n",
    "            test1[i][0],test1[i][1]=float(test1[i][1]),float(test1[i][0])   # Swap lon:lat to lat:lon\n",
    "        airsigmet_data_df.at[j,'lon:lat points']=test1\n",
    "\n",
    "    # shift cells for missing column\n",
    "    test2=airsigmet_data_df.iloc[j]['airsigmet_type']\n",
    "    if  pd.isna(test2)==True:    # Test if the cell is NaN\n",
    "        airsigmet_data_df.at[j,'airsigmet_type']=airsigmet_data_df.at[j,'severity']\n",
    "        airsigmet_data_df.at[j,'severity']=airsigmet_data_df.at[j,'hazard']\n",
    "        airsigmet_data_df.at[j,'hazard']=airsigmet_data_df.at[j,'movement_speed_kt']\n",
    "        airsigmet_data_df.at[j,'movement_speed_kt']=airsigmet_data_df.at[j,'movement_dir_degrees']\n",
    "        airsigmet_data_df.at[j,'movement_dir_degrees']=airsigmet_data_df.at[j,'max_ft_msl']\n",
    "        airsigmet_data_df.at[j,'max_ft_msl']=airsigmet_data_df.at[j,'min_ft_msl']\n",
    "        airsigmet_data_df.at[j,'min_ft_msl']=\"NaN\"\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "airsigmet_data_df.rename(columns={\"lon:lat points\":\"lat_lon_points\"}, inplace=True) # Update the column name\n",
    "airsigmet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a JSON format\n",
    "# airsigmet_json = json.loads(json.dumps(list(airsigmet_data_df.T.to_dict().values())))   # https://stackoverflow.com/questions/39257147/convert-pandas-dataframe-to-json-format answer #10 Amir.S\n",
    "# pprint(airsigmet_json, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary then to a JSON string\n",
    "airsigmet_string=json.dumps(list(airsigmet_data_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "# output_path = os.path.join(\"Resources\", \"airsigmet_data.json\")\n",
    "output_path = os.path.join(\"static\", \"airsigmet_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airsigmet_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__To download headwing and crosswind informations for all runways__ (Not used anymore: to be deleted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download the output of a query across multiple tables with the wind information relative to all runways.\n",
    "# # Will be used to update the makers for all airports.\n",
    "# # There are multiple rows per airport (one per runway).\n",
    "# # More parameters can be added to complete the info on the popup window.\n",
    "\n",
    "# load_dotenv()\n",
    "# db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "\n",
    "# query=\"\"\"\n",
    "# SELECT arpt_id, icao_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "# ROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "# ROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "# ROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "# ROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "# FROM apt_rwy\n",
    "# JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "# JOIN apt_rwy_end ON apt_base.site_no = apt_rwy_end.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "# FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "# WHERE facility_use_code='PU' AND arpt_status='O' AND site_type_code='A' AND (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND metar.wind_dir_degrees != 'VRB'\n",
    "# \"\"\"\n",
    "\n",
    "# engine=create_engine(db_url)\n",
    "# with engine.begin() as conn:\n",
    "#     results=conn.execute(\n",
    "#         text(query)\n",
    "#     )\n",
    "\n",
    "# rwy_wind_query_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\n",
    "# rwy_wind_string=json.dumps(list(rwy_wind_query_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"rwy_wind_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(rwy_wind_query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rwy_wind_query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Retrieve all data to position the circles for all airports and create the popup text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the output of a consolidated query across multiple tables with all information pertinent to an airport.\n",
    "# Will be used to update the makers for all airports.\n",
    "# There are multiple rows per airport (one per runway).\n",
    "# More parameters can be added to complete the info on the popup window.\n",
    "# Will be used to consolidate the information in the popups\n",
    "\n",
    "load_dotenv()\n",
    "db_url = os.environ.get(\"link_render\")\n",
    "\n",
    "query=\"\"\"\n",
    "-- Query to get METAR information for each airport as a VIEW\n",
    "DROP VIEW IF EXISTS all_circles_view;\n",
    "CREATE VIEW all_circles_view AS\n",
    "SELECT \n",
    "arpt_id, icao_id, metar.station_id, arpt_name, apt_rwy.rwy_id, apt_rwy.rwy_len, lat_decimal, metar.latitude, long_decimal, metar.longitude, metar.observation_time, metar.flight_category, metar.raw_text, elev, metar.visibility_statute_mi, metar.cloud_base_ft_agl\n",
    "-- , metar.wind_speed_kt\n",
    "FROM apt_rwy\n",
    "JOIN apt_base ON apt_base.site_no = apt_rwy.site_no\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND site_type_code='A' AND arpt_status='O' AND\n",
    "CASE\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Query to get wind information for each runway as a VIEW\n",
    "DROP VIEW IF EXISTS all_rwy_xwind_view;\n",
    "CREATE VIEW all_rwy_xwind_view AS\n",
    "SELECT arpt_id, icao_id, arpt_name, apt_base.tpa, apt_rwy.rwy_id, apt_rwy.rwy_len, apt_rwy.rwy_width, apt_rwy_end.rwy_end_id, apt_rwy_end.true_alignment, apt_rwy_end.right_hand_traffic_pat_flag, metar.wind_dir_degrees, metar.wind_speed_kt, metar.wind_gust_kt,\n",
    "\tROUND(metar.wind_speed_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"cross_wind\",\n",
    "\tROUND(metar.wind_speed_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"head_wind\",\n",
    "\tROUND(metar.wind_gust_kt*sin(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_cross_wind\",\n",
    "\tROUND(metar.wind_gust_kt*cos(radians(apt_rwy_end.true_alignment - (metar.wind_dir_degrees :: INTEGER)))) AS \"gust_head_wind\"\t\n",
    "FROM apt_rwy_end\n",
    "FULL JOIN apt_base ON apt_base.site_no = apt_rwy_end.site_no\n",
    "FULL JOIN apt_rwy ON apt_base.site_no = apt_rwy.site_no AND apt_rwy.rwy_id = apt_rwy_end.rwy_id\n",
    "FULL JOIN metar ON (RIGHT(metar.station_id, LENGTH(metar.station_id) - 1)) = apt_base.arpt_id\n",
    "WHERE facility_use_code='PU' AND arpt_status='O' AND\n",
    "CASE -- by not have the CASE, we were not providing the rwy length of the airports without METAR\n",
    "\tWHEN metar.station_id IS NOT NULL\n",
    "\tAND metar.wind_dir_degrees != 'VRB'\n",
    "\tTHEN (@(lat_decimal - metar.latitude) <1) AND (@(long_decimal - metar.longitude) <1) AND site_type_code='A'\n",
    "\t\n",
    "\tWHEN metar.station_id IS NULL\n",
    "\tTHEN site_type_code='A'\n",
    "END;\n",
    "\n",
    "\n",
    "-- Merge the two VIEWS\n",
    "SELECT \tall_circles_view.arpt_id, all_circles_view.icao_id, all_circles_view.station_id, all_circles_view.arpt_name, all_circles_view.lat_decimal, all_circles_view.long_decimal, all_circles_view.elev, all_rwy_xwind_view.tpa,\n",
    "\t\tall_circles_view.rwy_id, all_rwy_xwind_view.rwy_end_id, all_rwy_xwind_view.rwy_len, all_rwy_xwind_view.rwy_width, all_rwy_xwind_view.right_hand_traffic_pat_flag,\n",
    "\t\tall_rwy_xwind_view.cross_wind, all_rwy_xwind_view.head_wind, all_rwy_xwind_view.gust_cross_wind, all_rwy_xwind_view.gust_head_wind,\t\t\n",
    "\t\tall_rwy_xwind_view.true_alignment,\n",
    "\t\tall_rwy_xwind_view.wind_dir_degrees, all_rwy_xwind_view.wind_speed_kt, all_rwy_xwind_view.wind_gust_kt,\n",
    "\t\tall_circles_view.flight_category,  all_circles_view.visibility_statute_mi, all_circles_view.cloud_base_ft_agl,\t\t\n",
    "\t\tall_circles_view.observation_time, all_circles_view.raw_text\n",
    "FROM all_circles_view\n",
    "FULL JOIN all_rwy_xwind_view ON all_circles_view.arpt_id = all_rwy_xwind_view.arpt_id\n",
    "AND all_circles_view.rwy_id=all_rwy_xwind_view.rwy_id\n",
    "WHERE all_circles_view.rwy_id NOT LIKE 'H%'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "engine=create_engine(db_url)\n",
    "with engine.begin() as conn:\n",
    "    results=conn.execute(\n",
    "        text(query)\n",
    "    )\n",
    "\n",
    "airport_info_query_raw_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "# airport_info_string=json.dumps(list(airport_info_query_raw_df.T.to_dict().values()))\n",
    "\n",
    "# # open the file in write mode\n",
    "# output_path = os.path.join(\"\", \"airport_info_data.json\")\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     # write the JSON string to the file\n",
    "#     file.write(rwy_wind_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# # file is automatically closed after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport_info_query_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
       "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
       "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
       "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
       "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
       "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
       "       'raw_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_info_query_raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View length: 13570\n"
     ]
    }
   ],
   "source": [
    "# Consolidation of the database with only one row per airport regardless of the number of runways\n",
    "\n",
    "airport_info_query_df=pd.DataFrame(columns=['arpt_id', 'icao_id', 'station_id', 'arpt_name', 'lat_decimal',\n",
    "       'long_decimal', 'elev', 'tpa', 'rwy_id', 'rwy_end_id', 'rwy_len',\n",
    "       'rwy_width', 'right_hand_traffic_pat_flag', 'cross_wind', 'head_wind',\n",
    "       'gust_cross_wind', 'gust_head_wind', 'true_alignment',\n",
    "       'wind_dir_degrees', 'wind_speed_kt', 'wind_gust_kt', 'flight_category',\n",
    "       'visibility_statute_mi', 'cloud_base_ft_agl', 'observation_time',\n",
    "       'raw_text'])\n",
    "\n",
    "airport_info_query_df[\"popup_text\"]=np.nan\n",
    "\n",
    "first_row=True\n",
    "first_rwy=True\n",
    "\n",
    "a=len(airport_info_query_raw_df)\n",
    "print(f\"View length: {a}\")\n",
    "for i in range (a):\n",
    "    if first_row:\n",
    "       k=i\n",
    "       airport_info_query_df.loc[airport_info_query_raw_df.index[i]] = airport_info_query_raw_df.iloc[i]\n",
    "       popup_text=\"\"\"<div class=\"arpt_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_id\"]+'</div>'\n",
    "\n",
    "       if airport_info_query_raw_df.iloc[i][\"icao_id\"] is not None:\n",
    "           popup_text=popup_text+\"\"\"<div class=\"icao_id\"> / \"\"\"+airport_info_query_raw_df.iloc[i][\"icao_id\"]+'</div>'\n",
    "\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"arpt_name\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"arpt_name\"]+'</div>'\n",
    "       popup_text=popup_text+'<br>'+\"\"\"<div class=\"elev\">Airport Elevation: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"tpa\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+int(airport_info_query_raw_df.iloc[i][\"tpa\"])))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "       else:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"tpa\">TPA (estimated): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"elev\"]+1000))+\"\"\" (ft MSL)</div>\"\"\"\n",
    "             \n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"visibility_statute_mi\">Airport visibility: \"\"\"+airport_info_query_raw_df.iloc[i][\"visibility_statute_mi\"]+' (SM)</div>'\n",
    "\n",
    "       if pd.isna(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])==False:\n",
    "           popup_text=popup_text+'<br>'+\"\"\"<div class=\"cloud_base_ft_agl\">Airport ceiling: \"\"\"+str(airport_info_query_raw_df.iloc[i][\"cloud_base_ft_agl\"])+' (ft AGL)</div>'\n",
    "\n",
    "       first_row=False\n",
    "\n",
    "    if first_rwy:\n",
    "        popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_id\"> Runway \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_id\"]+' </div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_len\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_len\"> Runway length: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_len\"]))+' (ft)</div>'\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_width\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_width\"> Runway width: \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"rwy_width\"]))+' (ft)</div>'\n",
    "        first_rwy=False\n",
    "\n",
    "    if (pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False & pd.isna(airport_info_query_raw_df.iloc[i][\"true_alignment\"])==False) | (airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y'):\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"rwy_end_id\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"rwy_end_id\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"rwy_end_id\"]+' :</div>'\n",
    "            if airport_info_query_raw_df.iloc[i][\"right_hand_traffic_pat_flag\"]=='Y':\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"RP\"> RP </div>\"\"\"\n",
    "\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"cross_wind\">Crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"head_wind\">Headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_cross_wind\">Gust crosswind (neg. is from right): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_cross_wind\"]))+' (kt)</div>'\n",
    "\n",
    "        if pd.isna(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"])==False:\n",
    "            popup_text=popup_text+'<br>'+\"\"\"<div class=\"gust_head_wind\">Gust headwind (neg. is headwind): \"\"\"+str(int(airport_info_query_raw_df.iloc[i][\"gust_head_wind\"]))+' (kt)</div>'\n",
    "\n",
    "\n",
    "    if i<a-1:\n",
    "        if airport_info_query_raw_df.iloc[i+1][\"arpt_id\"]!=airport_info_query_raw_df.iloc[i][\"arpt_id\"]:\n",
    "            if pd.isna(airport_info_query_raw_df.iloc[i][\"raw_text\"])==False:\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"raw_text\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"raw_text\"]+'</div>'\n",
    "                popup_text=popup_text+'<br>'+\"\"\"<div class=\"observation_time\"> \"\"\"+airport_info_query_raw_df.iloc[i][\"observation_time\"]+'</div>'\n",
    "            else:\n",
    "                popup_text=popup_text+'<br> <div class=\"raw_text\">No weather information</div>'\n",
    "\n",
    "            airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "            # print(f\"k={k}, i={i}\")\n",
    "            # print(popup_text)\n",
    "            first_row=True\n",
    "            first_rwy=True\n",
    "        elif airport_info_query_raw_df.iloc[i+1][\"rwy_id\"]!=airport_info_query_raw_df.iloc[i][\"rwy_id\"]:\n",
    "            first_rwy=True\n",
    "\n",
    "    if i==a-1:\n",
    "        airport_info_query_df.at[k,\"popup_text\"]=popup_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert the dataframe to a dictionary then to a JSON string\t\t# The section below will be moved to be used on the consolidated DF.\n",
    "airport_info_string=json.dumps(list(airport_info_query_df.T.to_dict().values()))\n",
    "\n",
    "# open the file in write mode\n",
    "output_path = os.path.join(\"static\", \"airport_info_full_data.json\")\n",
    "with open(output_path, \"w\") as file:\n",
    "    # write the JSON string to the file\n",
    "    file.write(airport_info_string.replace(\"NaN\",\"null\"))\n",
    "\n",
    "# file is automatically closed after the with block\n",
    "        \n",
    "\n",
    "\n",
    "# airport_info_query_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport_info_query_df[airport_info_query_df['arpt_id']=='BLU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Write the json result files to AWS S3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "# key1 = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "# key2 = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):   # Inspired from https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-walkthroughs-managing-access-example1.html\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client(\n",
    "        's3',\n",
    "        # aws_access_key_id= os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        # aws_secret_access_key=os.environ.get(\"AWS_SECRET_ACCESS_KEY\") )\n",
    "        aws_access_key_id= os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        aws_secret_access_key= os.environ.get(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "upload_file(\"static/airsigmet_data.json\",'ga-weather', \"airsigmet_data.json\")\n",
    "upload_file(\"static/airport_info_full_data.json\",'ga-weather', \"airport_info_full_data.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
